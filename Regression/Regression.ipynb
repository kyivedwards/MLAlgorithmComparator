{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compare the performance of 8 Regressers across 8 Regression datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "datasets_name = ['wine', 'communities', 'qsar', 'facebook', 'bike', 'student', 'concrete', 'sgemm']\n",
    "models = ['Linear', 'SVM', 'DecisionTree', 'RandomForest', 'KNN', 'AdaBoost', 'GaussianProcess', 'NeuralNetwork']\n",
    "models_performances = {model:{dataset_name:0 for dataset_name in datasets_name} for model in models}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Flatten\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn import datasets, linear_model, metrics\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.svm import SVR\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor, AdaBoostRegressor\n",
    "from sklearn.neighbors import KNeighborsRegressor\n",
    "import sklearn.gaussian_process as gp\n",
    "from sklearn.metrics import accuracy_score, mean_squared_error, r2_score\n",
    "\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.compose import ColumnTransformer\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 1: Wine Quality"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  quality  \n",
       "0         9.4      5.0  \n",
       "1         9.8      5.0  \n",
       "2         9.8      5.0  \n",
       "3         9.8      6.0  \n",
       "4         9.4      5.0  \n",
       "...       ...      ...  \n",
       "1594     10.5      5.0  \n",
       "1595     11.2      6.0  \n",
       "1596     11.0      6.0  \n",
       "1597     10.2      5.0  \n",
       "1598     11.0      6.0  \n",
       "\n",
       "[1599 rows x 12 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "wine_df=pd.read_csv('datasets/winequality-red.csv', sep=';', dtype=float)\n",
    "wine_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       0.700\n",
       "1       0.880\n",
       "2       0.760\n",
       "3       0.280\n",
       "4       0.700\n",
       "        ...  \n",
       "1594    0.600\n",
       "1595    0.550\n",
       "1596    0.510\n",
       "1597    0.645\n",
       "1598    0.310\n",
       "Name: volatile acidity, Length: 1599, dtype: float64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wine_df['volatile acidity']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.880</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.99680</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.760</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.99700</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.99800</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.600</td>\n",
       "      <td>0.08</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.090</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99490</td>\n",
       "      <td>3.45</td>\n",
       "      <td>0.58</td>\n",
       "      <td>10.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.550</td>\n",
       "      <td>0.10</td>\n",
       "      <td>2.2</td>\n",
       "      <td>0.062</td>\n",
       "      <td>39.0</td>\n",
       "      <td>51.0</td>\n",
       "      <td>0.99512</td>\n",
       "      <td>3.52</td>\n",
       "      <td>0.76</td>\n",
       "      <td>11.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>5.9</td>\n",
       "      <td>0.645</td>\n",
       "      <td>0.12</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.075</td>\n",
       "      <td>32.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0.99547</td>\n",
       "      <td>3.57</td>\n",
       "      <td>0.71</td>\n",
       "      <td>10.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>6.0</td>\n",
       "      <td>0.310</td>\n",
       "      <td>0.47</td>\n",
       "      <td>3.6</td>\n",
       "      <td>0.067</td>\n",
       "      <td>18.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.99549</td>\n",
       "      <td>3.39</td>\n",
       "      <td>0.66</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1599 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0               7.4             0.700         0.00             1.9      0.076   \n",
       "1               7.8             0.880         0.00             2.6      0.098   \n",
       "2               7.8             0.760         0.04             2.3      0.092   \n",
       "3              11.2             0.280         0.56             1.9      0.075   \n",
       "4               7.4             0.700         0.00             1.9      0.076   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1594            6.2             0.600         0.08             2.0      0.090   \n",
       "1595            5.9             0.550         0.10             2.2      0.062   \n",
       "1596            6.3             0.510         0.13             2.3      0.076   \n",
       "1597            5.9             0.645         0.12             2.0      0.075   \n",
       "1598            6.0             0.310         0.47             3.6      0.067   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       "2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       "3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1594                 32.0                  44.0  0.99490  3.45       0.58   \n",
       "1595                 39.0                  51.0  0.99512  3.52       0.76   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "1597                 32.0                  44.0  0.99547  3.57       0.71   \n",
       "1598                 18.0                  42.0  0.99549  3.39       0.66   \n",
       "\n",
       "      alcohol  \n",
       "0         9.4  \n",
       "1         9.8  \n",
       "2         9.8  \n",
       "3         9.8  \n",
       "4         9.4  \n",
       "...       ...  \n",
       "1594     10.5  \n",
       "1595     11.2  \n",
       "1596     11.0  \n",
       "1597     10.2  \n",
       "1598     11.0  \n",
       "\n",
       "[1599 rows x 11 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X=wine_df.drop('quality', axis=1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       5.0\n",
       "1       5.0\n",
       "2       5.0\n",
       "3       6.0\n",
       "4       5.0\n",
       "       ... \n",
       "1594    5.0\n",
       "1595    6.0\n",
       "1596    6.0\n",
       "1597    5.0\n",
       "1598    6.0\n",
       "Name: quality, Length: 1599, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y=wine_df['quality']\n",
    "Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10.0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y.iloc[1]+Y.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train, x_test, y_train, y_test = train_test_split(X,Y, train_size=0.8, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_wine = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=10000).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_wine = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_wine = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_wine= RandomForestRegressor(random_state=0)\n",
    "r_f_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_wine = KNeighborsRegressor(n_neighbors=8)\n",
    "# n_neighbors=8\n",
    "\n",
    "kn_wine.fit(x_train,y_train)\n",
    "# print('Variance score: {}'.format(kn.score(x_test, y_test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_wine = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_wine.fit(x_train,y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_wine = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_wine.fit(x_train, y_train)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense (Dense)               (None, 128)               1536      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_2 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,401\n",
      "Trainable params: 166,401\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "32/32 [==============================] - 1s 13ms/step - loss: 2.1010 - mean_absolute_error: 2.1010 - val_loss: 0.6702 - val_mean_absolute_error: 0.6702\n",
      "Epoch 2/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.7022 - mean_absolute_error: 0.7022 - val_loss: 0.6457 - val_mean_absolute_error: 0.6457\n",
      "Epoch 3/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6260 - mean_absolute_error: 0.6260 - val_loss: 0.6119 - val_mean_absolute_error: 0.6119\n",
      "Epoch 4/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6103 - mean_absolute_error: 0.6103 - val_loss: 0.6769 - val_mean_absolute_error: 0.6769\n",
      "Epoch 5/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6287 - mean_absolute_error: 0.6287 - val_loss: 0.6309 - val_mean_absolute_error: 0.6309\n",
      "Epoch 6/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5876 - mean_absolute_error: 0.5876 - val_loss: 0.5508 - val_mean_absolute_error: 0.5508\n",
      "Epoch 7/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5865 - mean_absolute_error: 0.5865 - val_loss: 0.6827 - val_mean_absolute_error: 0.6827\n",
      "Epoch 8/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5930 - mean_absolute_error: 0.5930 - val_loss: 0.6037 - val_mean_absolute_error: 0.6037\n",
      "Epoch 9/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5910 - mean_absolute_error: 0.5910 - val_loss: 0.6303 - val_mean_absolute_error: 0.6303\n",
      "Epoch 10/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5768 - mean_absolute_error: 0.5768 - val_loss: 0.6283 - val_mean_absolute_error: 0.6283\n",
      "Epoch 11/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5994 - mean_absolute_error: 0.5994 - val_loss: 0.5822 - val_mean_absolute_error: 0.5822\n",
      "Epoch 12/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5793 - mean_absolute_error: 0.5793 - val_loss: 0.7118 - val_mean_absolute_error: 0.7118\n",
      "Epoch 13/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.6431 - mean_absolute_error: 0.6431 - val_loss: 0.8012 - val_mean_absolute_error: 0.8012\n",
      "Epoch 14/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5724 - mean_absolute_error: 0.5724 - val_loss: 0.5320 - val_mean_absolute_error: 0.5320\n",
      "Epoch 15/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5439 - mean_absolute_error: 0.5439 - val_loss: 0.5345 - val_mean_absolute_error: 0.5345\n",
      "Epoch 16/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5558 - mean_absolute_error: 0.5558 - val_loss: 0.5264 - val_mean_absolute_error: 0.5264\n",
      "Epoch 17/20\n",
      "32/32 [==============================] - 0s 5ms/step - loss: 0.5491 - mean_absolute_error: 0.5491 - val_loss: 0.5543 - val_mean_absolute_error: 0.5543\n",
      "Epoch 18/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5442 - mean_absolute_error: 0.5442 - val_loss: 0.5281 - val_mean_absolute_error: 0.5281\n",
      "Epoch 19/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5494 - mean_absolute_error: 0.5494 - val_loss: 0.5396 - val_mean_absolute_error: 0.5396\n",
      "Epoch 20/20\n",
      "32/32 [==============================] - 0s 6ms/step - loss: 0.5531 - mean_absolute_error: 0.5531 - val_loss: 0.5317 - val_mean_absolute_error: 0.5317\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245521716d0>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model.add(Dense(128, kernel_initializer='normal',input_dim = x_train.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model.summary()\n",
    "NN_model.fit(x_train, y_train, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3844711978201255\n",
      "R2: 0.3283887639580202\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_wine.predict(x_test)\n",
    "models_performances[\"Linear\"][\"wine\"] = r2_score(y_test, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.698181023075342\n",
      "R2: -0.21961338728957736\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_wine.predict(x_test)\n",
    "models_performances[\"SVM\"][\"wine\"] = r2_score(y_test, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.621875\n",
      "R2: -0.08631866257250076\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_wine.predict(x_test)\n",
    "models_performances[\"DecisionTree\"][\"wine\"] = r2_score(y_test, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3242909375\n",
      "R2: 0.4335142954622996\n"
     ]
    }
   ],
   "source": [
    "output = r_f_wine.predict(x_test)\n",
    "models_performances[\"RandomForest\"][\"wine\"] = r2_score(y_test, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.493798828125\n",
      "R2: 0.137410440122825\n"
     ]
    }
   ],
   "source": [
    "output = kn_wine.predict(x_test)\n",
    "models_performances[\"KNN\"][\"wine\"] = r2_score(y_test, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.40642325152249426\n",
      "R2: 0.2900419488928112\n"
     ]
    }
   ],
   "source": [
    "output = ada_wine.predict(x_test)\n",
    "models_performances[\"AdaBoost\"][\"wine\"] = r2_score(y_test, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.4472905501833061\n",
      "R2: 0.21865315014038644\n"
     ]
    }
   ],
   "source": [
    "output = gpr_wine.predict(x_test)\n",
    "models_performances[\"GaussianProcess\"][\"wine\"] = r2_score(y_test, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.41675939806891693\n",
      "R2: 0.27198631248282\n"
     ]
    }
   ],
   "source": [
    "output = NN_model.predict(x_test)\n",
    "models_performances[\"NeuralNetwork\"][\"wine\"] = r2_score(y_test, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test, output)))\n",
    "print(f'R2: {r2_score(y_test, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 2: Communities and Crime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = list()\n",
    "with open(\"datasets/communities.names\",\"r\") as f:\n",
    "    for l in f.readlines():\n",
    "        l = l.split(\" \")\n",
    "        if l[0] == \"@attribute\":\n",
    "            names.append(l[1])\n",
    "comm_dataset = pd.read_csv(\"datasets/communities.data\", delimiter=',', names=names)\n",
    "\n",
    "# feature selection\n",
    "L_drop = [comm_dataset.columns[0], comm_dataset.columns[1], comm_dataset.columns[2], comm_dataset.columns[3]]\n",
    "for i in range(11,len(comm_dataset.columns)):\n",
    "    L_drop.append(comm_dataset.columns[i])\n",
    "comm_df = comm_dataset.drop(columns=L_drop)\n",
    "\n",
    "comm_df['y'] = comm_dataset['state']\n",
    "comm_df = comm_df.astype(float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold</th>\n",
       "      <th>population</th>\n",
       "      <th>householdsize</th>\n",
       "      <th>racepctblack</th>\n",
       "      <th>racePctWhite</th>\n",
       "      <th>racePctAsian</th>\n",
       "      <th>racePctHisp</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.33</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.90</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.17</td>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.74</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.07</td>\n",
       "      <td>53.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.42</td>\n",
       "      <td>0.49</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.04</td>\n",
       "      <td>24.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.04</td>\n",
       "      <td>0.77</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.12</td>\n",
       "      <td>0.10</td>\n",
       "      <td>34.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.01</td>\n",
       "      <td>0.55</td>\n",
       "      <td>0.02</td>\n",
       "      <td>0.95</td>\n",
       "      <td>0.09</td>\n",
       "      <td>0.05</td>\n",
       "      <td>42.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold  population  householdsize  racepctblack  racePctWhite  racePctAsian  \\\n",
       "0   1.0        0.19           0.33          0.02          0.90          0.12   \n",
       "1   1.0        0.00           0.16          0.12          0.74          0.45   \n",
       "2   1.0        0.00           0.42          0.49          0.56          0.17   \n",
       "3   1.0        0.04           0.77          1.00          0.08          0.12   \n",
       "4   1.0        0.01           0.55          0.02          0.95          0.09   \n",
       "\n",
       "   racePctHisp     y  \n",
       "0         0.17   8.0  \n",
       "1         0.07  53.0  \n",
       "2         0.04  24.0  \n",
       "3         0.10  34.0  \n",
       "4         0.05  42.0  "
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comm_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "X0=comm_df.drop('y', axis=1)\n",
    "Y0=comm_df['y']\n",
    "\n",
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train0, x_test0, y_train0, y_test0 = train_test_split(X0,Y0, train_size=0.8, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_comm_df = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_comm_df  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_comm_df  = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_comm_df= RandomForestRegressor(random_state=0)\n",
    "r_f_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_comm_df = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_comm_df.fit(x_train0,y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_comm_df  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_comm_df .fit(x_train0,y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_comm_df  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_comm_df.fit(x_train0, y_train0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_5 (Dense)             (None, 128)               1024      \n",
      "                                                                 \n",
      " dense_6 (Dense)             (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_7 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_8 (Dense)             (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_9 (Dense)             (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 165,889\n",
      "Trainable params: 165,889\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "40/40 [==============================] - 1s 11ms/step - loss: 20.8613 - mean_absolute_error: 20.8613 - val_loss: 16.6074 - val_mean_absolute_error: 16.6074\n",
      "Epoch 2/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 14.8608 - mean_absolute_error: 14.8608 - val_loss: 16.0144 - val_mean_absolute_error: 16.0144\n",
      "Epoch 3/20\n",
      "40/40 [==============================] - ETA: 0s - loss: 13.9399 - mean_absolute_error: 13.939 - 0s 5ms/step - loss: 13.8158 - mean_absolute_error: 13.8158 - val_loss: 13.8946 - val_mean_absolute_error: 13.8946\n",
      "Epoch 4/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.2045 - mean_absolute_error: 13.2045 - val_loss: 13.4716 - val_mean_absolute_error: 13.4716\n",
      "Epoch 5/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.0779 - mean_absolute_error: 13.0779 - val_loss: 13.4730 - val_mean_absolute_error: 13.4730\n",
      "Epoch 6/20\n",
      "40/40 [==============================] - 0s 6ms/step - loss: 13.1332 - mean_absolute_error: 13.1332 - val_loss: 13.5942 - val_mean_absolute_error: 13.5942\n",
      "Epoch 7/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 13.4123 - mean_absolute_error: 13.4123 - val_loss: 13.3083 - val_mean_absolute_error: 13.3083\n",
      "Epoch 8/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.9488 - mean_absolute_error: 12.9488 - val_loss: 13.6420 - val_mean_absolute_error: 13.6420\n",
      "Epoch 9/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.8431 - mean_absolute_error: 12.8431 - val_loss: 13.3990 - val_mean_absolute_error: 13.3990\n",
      "Epoch 10/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.8935 - mean_absolute_error: 12.8935 - val_loss: 13.3798 - val_mean_absolute_error: 13.3798\n",
      "Epoch 11/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.8875 - mean_absolute_error: 12.8875 - val_loss: 13.2382 - val_mean_absolute_error: 13.2382\n",
      "Epoch 12/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.7930 - mean_absolute_error: 12.7930 - val_loss: 13.2702 - val_mean_absolute_error: 13.2702\n",
      "Epoch 13/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.9808 - mean_absolute_error: 12.9808 - val_loss: 13.6554 - val_mean_absolute_error: 13.6554\n",
      "Epoch 14/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.7647 - mean_absolute_error: 12.7647 - val_loss: 13.2432 - val_mean_absolute_error: 13.2432\n",
      "Epoch 15/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.6769 - mean_absolute_error: 12.6769 - val_loss: 13.3961 - val_mean_absolute_error: 13.3961\n",
      "Epoch 16/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.7815 - mean_absolute_error: 12.7815 - val_loss: 13.1840 - val_mean_absolute_error: 13.1840\n",
      "Epoch 17/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.7375 - mean_absolute_error: 12.7375 - val_loss: 13.1050 - val_mean_absolute_error: 13.1050\n",
      "Epoch 18/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.4979 - mean_absolute_error: 12.4979 - val_loss: 13.6027 - val_mean_absolute_error: 13.6027\n",
      "Epoch 19/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.6563 - mean_absolute_error: 12.6563 - val_loss: 13.1810 - val_mean_absolute_error: 13.1810\n",
      "Epoch 20/20\n",
      "40/40 [==============================] - 0s 5ms/step - loss: 12.8613 - mean_absolute_error: 12.8613 - val_loss: 13.4102 - val_mean_absolute_error: 13.4102\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24552d2c820>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model0 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model0.add(Dense(128, kernel_initializer='normal',input_dim = x_train0.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model0.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model0.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model0.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model0.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model0.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model0.summary()\n",
    "NN_model0.fit(x_train0, y_train0, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 235.9396685440531\n",
      "R2: 0.15036327727266985\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_comm_df.predict(x_test0)\n",
    "models_performances[\"Linear\"][\"communities\"] = r2_score(y_test0, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 255.00016321802306\n",
      "R2: 0.08172498372802217\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_comm_df.predict(x_test0)\n",
    "models_performances[\"SVM\"][\"communities\"] = r2_score(y_test0, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 418.4636591478697\n",
      "R2: -0.5069195194384963\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_comm_df.predict(x_test0)\n",
    "models_performances[\"DecisionTree\"][\"communities\"] = r2_score(y_test0, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 211.2767989974937\n",
      "R2: 0.23917614957980327\n"
     ]
    }
   ],
   "source": [
    "output = r_f_comm_df.predict(x_test0)\n",
    "models_performances[\"RandomForest\"][\"communities\"] = r2_score(y_test0, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 266.4591557017544\n",
      "R2: 0.040460278730707344\n"
     ]
    }
   ],
   "source": [
    "output = kn_comm_df.predict(x_test0)\n",
    "models_performances[\"KNN\"][\"communities\"] = r2_score(y_test0, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 235.91998829925294\n",
      "R2: 0.1504341473336377\n"
     ]
    }
   ],
   "source": [
    "output = ada_comm_df.predict(x_test0)\n",
    "models_performances[\"AdaBoost\"][\"communities\"] = r2_score(y_test0, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 230.3510320819913\n",
      "R2: 0.17048838297211288\n"
     ]
    }
   ],
   "source": [
    "output = gpr_comm_df.predict(x_test0)\n",
    "models_performances[\"GaussianProcess\"][\"communities\"] = r2_score(y_test0, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 244.6513435512096\n",
      "R2: 0.11899187182728133\n"
     ]
    }
   ],
   "source": [
    "output = NN_model0.predict(x_test0)\n",
    "models_performances[\"NeuralNetwork\"][\"communities\"] = r2_score(y_test0, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test0, output)))\n",
    "print(f'R2: {r2_score(y_test0, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 3: QSAR aquatic toxicity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TPSA</th>\n",
       "      <th>SAacc</th>\n",
       "      <th>H-050</th>\n",
       "      <th>MLOGP</th>\n",
       "      <th>RDCHI</th>\n",
       "      <th>GATS1p</th>\n",
       "      <th>nN</th>\n",
       "      <th>C-040</th>\n",
       "      <th>LC50</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.419</td>\n",
       "      <td>1.225</td>\n",
       "      <td>0.667</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.638</td>\n",
       "      <td>1.401</td>\n",
       "      <td>0.632</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.330</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.799</td>\n",
       "      <td>2.930</td>\n",
       "      <td>0.486</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.453</td>\n",
       "      <td>2.887</td>\n",
       "      <td>0.495</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.068</td>\n",
       "      <td>2.758</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.979</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>541</th>\n",
       "      <td>24.06</td>\n",
       "      <td>35.776</td>\n",
       "      <td>2.0</td>\n",
       "      <td>3.326</td>\n",
       "      <td>2.837</td>\n",
       "      <td>0.849</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>542</th>\n",
       "      <td>9.23</td>\n",
       "      <td>11.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.275</td>\n",
       "      <td>2.727</td>\n",
       "      <td>0.874</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>543</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.165</td>\n",
       "      <td>3.111</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.219</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>544</th>\n",
       "      <td>13.14</td>\n",
       "      <td>9.507</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.859</td>\n",
       "      <td>2.614</td>\n",
       "      <td>0.827</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>545</th>\n",
       "      <td>0.00</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.255</td>\n",
       "      <td>1.800</td>\n",
       "      <td>0.917</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.480</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>546 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      TPSA   SAacc  H-050  MLOGP  RDCHI  GATS1p   nN  C-040   LC50\n",
       "0     0.00   0.000    0.0  2.419  1.225   0.667  0.0    0.0  3.740\n",
       "1     0.00   0.000    0.0  2.638  1.401   0.632  0.0    0.0  4.330\n",
       "2     9.23  11.000    0.0  5.799  2.930   0.486  0.0    0.0  7.019\n",
       "3     9.23  11.000    0.0  5.453  2.887   0.495  0.0    0.0  6.723\n",
       "4     9.23  11.000    0.0  4.068  2.758   0.695  0.0    0.0  5.979\n",
       "..     ...     ...    ...    ...    ...     ...  ...    ...    ...\n",
       "541  24.06  35.776    2.0  3.326  2.837   0.849  2.0    0.0  4.651\n",
       "542   9.23  11.000    0.0  3.275  2.727   0.874  0.0    0.0  3.953\n",
       "543   0.00   0.000    0.0  5.165  3.111   0.732  0.0    0.0  6.219\n",
       "544  13.14   9.507    0.0  2.859  2.614   0.827  0.0    0.0  4.995\n",
       "545   0.00   0.000    0.0  2.255  1.800   0.917  0.0    0.0  2.480\n",
       "\n",
       "[546 rows x 9 columns]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#immporting data\n",
    "toxic_df=pd.read_csv('datasets/qsar_aquatic_toxicity.csv',  sep=';', \n",
    "                     names=[\"TPSA\",\"SAacc\", \"H-050\", \"MLOGP\", \"RDCHI\", \"GATS1p\", \"nN\", \"C-040\", \"LC50\"],\n",
    "                    dtype=float)\n",
    "toxic_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X1=toxic_df.drop('LC50', axis=1)\n",
    "Y1=toxic_df['LC50']\n",
    "\n",
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train1, x_test1, y_train1, y_test1 = train_test_split(X1,Y1, train_size=0.8, random_state=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_toxic = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_toxic  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_toxic  = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_toxic= RandomForestRegressor(random_state=0)\n",
    "r_f_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_toxic = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_toxic.fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_toxic  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_toxic .fit(x_train1,y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_toxic  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_toxic.fit(x_train1, y_train1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_10 (Dense)            (None, 128)               1152      \n",
      "                                                                 \n",
      " dense_11 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_12 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_13 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_14 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,017\n",
      "Trainable params: 166,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "11/11 [==============================] - 1s 29ms/step - loss: 3.3065 - mean_absolute_error: 3.3065 - val_loss: 2.7670 - val_mean_absolute_error: 2.7670\n",
      "Epoch 2/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 2.6503 - mean_absolute_error: 2.6503 - val_loss: 2.1533 - val_mean_absolute_error: 2.1533\n",
      "Epoch 3/20\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.6322 - mean_absolute_error: 1.6322 - val_loss: 1.7884 - val_mean_absolute_error: 1.7884\n",
      "Epoch 4/20\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.4387 - mean_absolute_error: 1.4387 - val_loss: 1.2249 - val_mean_absolute_error: 1.2249\n",
      "Epoch 5/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.1257 - mean_absolute_error: 1.1257 - val_loss: 1.0574 - val_mean_absolute_error: 1.0574\n",
      "Epoch 6/20\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 1.0116 - mean_absolute_error: 1.0116 - val_loss: 1.3116 - val_mean_absolute_error: 1.3116\n",
      "Epoch 7/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 1.0971 - mean_absolute_error: 1.0971 - val_loss: 1.1914 - val_mean_absolute_error: 1.1914\n",
      "Epoch 8/20\n",
      "11/11 [==============================] - 0s 6ms/step - loss: 1.0028 - mean_absolute_error: 1.0028 - val_loss: 1.0287 - val_mean_absolute_error: 1.0287\n",
      "Epoch 9/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9503 - mean_absolute_error: 0.9503 - val_loss: 1.0007 - val_mean_absolute_error: 1.0007\n",
      "Epoch 10/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9902 - mean_absolute_error: 0.9902 - val_loss: 1.0537 - val_mean_absolute_error: 1.0537\n",
      "Epoch 11/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9490 - mean_absolute_error: 0.9490 - val_loss: 0.9730 - val_mean_absolute_error: 0.9730\n",
      "Epoch 12/20\n",
      "11/11 [==============================] - 0s 9ms/step - loss: 0.9755 - mean_absolute_error: 0.9755 - val_loss: 0.9534 - val_mean_absolute_error: 0.9534\n",
      "Epoch 13/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9394 - mean_absolute_error: 0.9394 - val_loss: 1.0277 - val_mean_absolute_error: 1.0277\n",
      "Epoch 14/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8978 - mean_absolute_error: 0.8978 - val_loss: 0.9948 - val_mean_absolute_error: 0.9948\n",
      "Epoch 15/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9108 - mean_absolute_error: 0.9108 - val_loss: 0.9910 - val_mean_absolute_error: 0.9910\n",
      "Epoch 16/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9036 - mean_absolute_error: 0.9036 - val_loss: 1.1315 - val_mean_absolute_error: 1.1315\n",
      "Epoch 17/20\n",
      "11/11 [==============================] - 0s 8ms/step - loss: 0.9713 - mean_absolute_error: 0.9713 - val_loss: 1.2908 - val_mean_absolute_error: 1.2908\n",
      "Epoch 18/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9517 - mean_absolute_error: 0.9517 - val_loss: 0.9449 - val_mean_absolute_error: 0.9449\n",
      "Epoch 19/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.9074 - mean_absolute_error: 0.9074 - val_loss: 1.0118 - val_mean_absolute_error: 1.0118\n",
      "Epoch 20/20\n",
      "11/11 [==============================] - 0s 7ms/step - loss: 0.8827 - mean_absolute_error: 0.8827 - val_loss: 0.9420 - val_mean_absolute_error: 0.9420\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24552ec6be0>"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model1 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model1.add(Dense(128, kernel_initializer='normal',input_dim = x_train1.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model1.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model1.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model1.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model1.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model1.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model1.summary()\n",
    "NN_model1.fit(x_train1, y_train1, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.4197727187578568\n",
      "R2: 0.44023740559019386\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_toxic.predict(x_test1)\n",
    "models_performances[\"Linear\"][\"qsar\"] = r2_score(y_test1, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.966374386707823\n",
      "R2: 0.22473307611689097\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_toxic.predict(x_test1)\n",
    "models_performances[\"SVM\"][\"qsar\"] = r2_score(y_test1, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.4739484641414147\n",
      "R2: 0.024615847009991754\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_toxic.predict(x_test1)\n",
    "models_performances[\"DecisionTree\"][\"qsar\"] = r2_score(y_test1, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.595474133895092\n",
      "R2: 0.37096499411243333\n"
     ]
    }
   ],
   "source": [
    "output = r_f_toxic.predict(x_test1)\n",
    "models_performances[\"RandomForest\"][\"qsar\"] = r2_score(y_test1, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.9766162769886362\n",
      "R2: 0.2206950867968367\n"
     ]
    }
   ],
   "source": [
    "output = kn_toxic.predict(x_test1)\n",
    "models_performances[\"KNN\"][\"qsar\"] = r2_score(y_test1, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.6538334205235925\n",
      "R2: 0.34795613835722816\n"
     ]
    }
   ],
   "source": [
    "output = ada_toxic.predict(x_test1)\n",
    "models_performances[\"AdaBoost\"][\"qsar\"] = r2_score(y_test1, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.6485561270616855\n",
      "R2: 0.35003677523711096\n"
     ]
    }
   ],
   "source": [
    "output = gpr_toxic.predict(x_test1)\n",
    "models_performances[\"GaussianProcess\"][\"qsar\"] = r2_score(y_test1, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.4391318881585005\n",
      "R2: 0.43260481852456556\n"
     ]
    }
   ],
   "source": [
    "output = NN_model1.predict(x_test1)\n",
    "models_performances[\"NeuralNetwork\"][\"qsar\"] = r2_score(y_test1, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test1, output)))\n",
    "print(f'R2: {r2_score(y_test1, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 4: Facebook metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "fb_df = pd.read_csv('datasets/dataset_Facebook.csv', sep=';', header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page total likes</th>\n",
       "      <th>Type_Link</th>\n",
       "      <th>Type_Photo</th>\n",
       "      <th>Type_Status</th>\n",
       "      <th>Type_Video</th>\n",
       "      <th>Category</th>\n",
       "      <th>Post Month</th>\n",
       "      <th>Post Weekday</th>\n",
       "      <th>Post Hour</th>\n",
       "      <th>Paid</th>\n",
       "      <th>...</th>\n",
       "      <th>Lifetime Engaged Users</th>\n",
       "      <th>Lifetime Post Consumers</th>\n",
       "      <th>Lifetime Post Consumptions</th>\n",
       "      <th>Lifetime Post Impressions by people who have liked your Page</th>\n",
       "      <th>Lifetime Post reach by people who like your Page</th>\n",
       "      <th>Lifetime People who have liked your Page and engaged with your post</th>\n",
       "      <th>comment</th>\n",
       "      <th>like</th>\n",
       "      <th>share</th>\n",
       "      <th>Total Interactions</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>178</td>\n",
       "      <td>109</td>\n",
       "      <td>159</td>\n",
       "      <td>3078</td>\n",
       "      <td>1640</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1457</td>\n",
       "      <td>1361</td>\n",
       "      <td>1674</td>\n",
       "      <td>11710</td>\n",
       "      <td>6112</td>\n",
       "      <td>1108</td>\n",
       "      <td>5</td>\n",
       "      <td>130.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>177</td>\n",
       "      <td>113</td>\n",
       "      <td>154</td>\n",
       "      <td>2812</td>\n",
       "      <td>1503</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2211</td>\n",
       "      <td>790</td>\n",
       "      <td>1119</td>\n",
       "      <td>61027</td>\n",
       "      <td>32048</td>\n",
       "      <td>1386</td>\n",
       "      <td>58</td>\n",
       "      <td>1572.0</td>\n",
       "      <td>147.0</td>\n",
       "      <td>1777</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>671</td>\n",
       "      <td>410</td>\n",
       "      <td>580</td>\n",
       "      <td>6228</td>\n",
       "      <td>3200</td>\n",
       "      <td>396</td>\n",
       "      <td>19</td>\n",
       "      <td>325.0</td>\n",
       "      <td>49.0</td>\n",
       "      <td>393</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>85093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>733</td>\n",
       "      <td>708</td>\n",
       "      <td>985</td>\n",
       "      <td>4750</td>\n",
       "      <td>2876</td>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>53.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>84</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>537</td>\n",
       "      <td>508</td>\n",
       "      <td>687</td>\n",
       "      <td>3961</td>\n",
       "      <td>2104</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>625</td>\n",
       "      <td>572</td>\n",
       "      <td>795</td>\n",
       "      <td>4742</td>\n",
       "      <td>2388</td>\n",
       "      <td>363</td>\n",
       "      <td>4</td>\n",
       "      <td>93.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>626</td>\n",
       "      <td>574</td>\n",
       "      <td>832</td>\n",
       "      <td>4534</td>\n",
       "      <td>2452</td>\n",
       "      <td>370</td>\n",
       "      <td>7</td>\n",
       "      <td>91.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>564</td>\n",
       "      <td>524</td>\n",
       "      <td>743</td>\n",
       "      <td>3861</td>\n",
       "      <td>2200</td>\n",
       "      <td>316</td>\n",
       "      <td>0</td>\n",
       "      <td>91.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Page total likes  Type_Link  Type_Photo  Type_Status  Type_Video  \\\n",
       "0              139441          0           1            0           0   \n",
       "1              139441          0           0            1           0   \n",
       "2              139441          0           1            0           0   \n",
       "3              139441          0           1            0           0   \n",
       "4              139441          0           1            0           0   \n",
       "..                ...        ...         ...          ...         ...   \n",
       "495             85093          0           1            0           0   \n",
       "496             81370          0           1            0           0   \n",
       "497             81370          0           1            0           0   \n",
       "498             81370          0           1            0           0   \n",
       "499             81370          0           1            0           0   \n",
       "\n",
       "     Category  Post Month  Post Weekday  Post Hour  Paid  ...  \\\n",
       "0           2          12             4          3   0.0  ...   \n",
       "1           2          12             3         10   0.0  ...   \n",
       "2           3          12             3          3   0.0  ...   \n",
       "3           2          12             2         10   1.0  ...   \n",
       "4           2          12             2          3   0.0  ...   \n",
       "..        ...         ...           ...        ...   ...  ...   \n",
       "495         3           1             7          2   0.0  ...   \n",
       "496         2           1             5          8   0.0  ...   \n",
       "497         1           1             5          2   0.0  ...   \n",
       "498         3           1             4         11   0.0  ...   \n",
       "499         2           1             4          4   NaN  ...   \n",
       "\n",
       "     Lifetime Engaged Users  Lifetime Post Consumers  \\\n",
       "0                       178                      109   \n",
       "1                      1457                     1361   \n",
       "2                       177                      113   \n",
       "3                      2211                      790   \n",
       "4                       671                      410   \n",
       "..                      ...                      ...   \n",
       "495                     733                      708   \n",
       "496                     537                      508   \n",
       "497                     625                      572   \n",
       "498                     626                      574   \n",
       "499                     564                      524   \n",
       "\n",
       "     Lifetime Post Consumptions  \\\n",
       "0                           159   \n",
       "1                          1674   \n",
       "2                           154   \n",
       "3                          1119   \n",
       "4                           580   \n",
       "..                          ...   \n",
       "495                         985   \n",
       "496                         687   \n",
       "497                         795   \n",
       "498                         832   \n",
       "499                         743   \n",
       "\n",
       "     Lifetime Post Impressions by people who have liked your Page  \\\n",
       "0                                                 3078              \n",
       "1                                                11710              \n",
       "2                                                 2812              \n",
       "3                                                61027              \n",
       "4                                                 6228              \n",
       "..                                                 ...              \n",
       "495                                               4750              \n",
       "496                                               3961              \n",
       "497                                               4742              \n",
       "498                                               4534              \n",
       "499                                               3861              \n",
       "\n",
       "     Lifetime Post reach by people who like your Page  \\\n",
       "0                                                1640   \n",
       "1                                                6112   \n",
       "2                                                1503   \n",
       "3                                               32048   \n",
       "4                                                3200   \n",
       "..                                                ...   \n",
       "495                                              2876   \n",
       "496                                              2104   \n",
       "497                                              2388   \n",
       "498                                              2452   \n",
       "499                                              2200   \n",
       "\n",
       "     Lifetime People who have liked your Page and engaged with your post  \\\n",
       "0                                                  119                     \n",
       "1                                                 1108                     \n",
       "2                                                  132                     \n",
       "3                                                 1386                     \n",
       "4                                                  396                     \n",
       "..                                                 ...                     \n",
       "495                                                392                     \n",
       "496                                                301                     \n",
       "497                                                363                     \n",
       "498                                                370                     \n",
       "499                                                316                     \n",
       "\n",
       "     comment    like  share  Total Interactions  \n",
       "0          4    79.0   17.0                 100  \n",
       "1          5   130.0   29.0                 164  \n",
       "2          0    66.0   14.0                  80  \n",
       "3         58  1572.0  147.0                1777  \n",
       "4         19   325.0   49.0                 393  \n",
       "..       ...     ...    ...                 ...  \n",
       "495        5    53.0   26.0                  84  \n",
       "496        0    53.0   22.0                  75  \n",
       "497        4    93.0   18.0                 115  \n",
       "498        7    91.0   38.0                 136  \n",
       "499        0    91.0   28.0                 119  \n",
       "\n",
       "[500 rows x 22 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features_cat = [\"Type\"]\n",
    "\n",
    "# replace the columns with categorical values by its one hot encoding\n",
    "for feat in features_cat:\n",
    "    tmp_df = pd.get_dummies(fb_df[feat], prefix=feat)\n",
    "    idx = fb_df.columns.get_loc(feat)\n",
    "    for i, col in enumerate(tmp_df.columns):\n",
    "        fb_df.insert(idx+i, col, tmp_df[col])\n",
    "    fb_df = fb_df.drop(feat, axis=1)\n",
    "\n",
    "fb_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete every row containing at least one 'Nan'\n",
    "fb_df = fb_df.dropna(axis=0).astype(int)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Page total likes</th>\n",
       "      <th>Type_Link</th>\n",
       "      <th>Type_Photo</th>\n",
       "      <th>Type_Status</th>\n",
       "      <th>Type_Video</th>\n",
       "      <th>Category</th>\n",
       "      <th>Post Month</th>\n",
       "      <th>Post Weekday</th>\n",
       "      <th>Post Hour</th>\n",
       "      <th>Paid</th>\n",
       "      <th>...</th>\n",
       "      <th>Lifetime Post Total Impressions</th>\n",
       "      <th>Lifetime Engaged Users</th>\n",
       "      <th>Lifetime Post Consumers</th>\n",
       "      <th>Lifetime Post Consumptions</th>\n",
       "      <th>Lifetime Post Impressions by people who have liked your Page</th>\n",
       "      <th>Lifetime Post reach by people who like your Page</th>\n",
       "      <th>Lifetime People who have liked your Page and engaged with your post</th>\n",
       "      <th>comment</th>\n",
       "      <th>like</th>\n",
       "      <th>share</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5091</td>\n",
       "      <td>178</td>\n",
       "      <td>109</td>\n",
       "      <td>159</td>\n",
       "      <td>3078</td>\n",
       "      <td>1640</td>\n",
       "      <td>119</td>\n",
       "      <td>4</td>\n",
       "      <td>79</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>19057</td>\n",
       "      <td>1457</td>\n",
       "      <td>1361</td>\n",
       "      <td>1674</td>\n",
       "      <td>11710</td>\n",
       "      <td>6112</td>\n",
       "      <td>1108</td>\n",
       "      <td>5</td>\n",
       "      <td>130</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>12</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4373</td>\n",
       "      <td>177</td>\n",
       "      <td>113</td>\n",
       "      <td>154</td>\n",
       "      <td>2812</td>\n",
       "      <td>1503</td>\n",
       "      <td>132</td>\n",
       "      <td>0</td>\n",
       "      <td>66</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>87991</td>\n",
       "      <td>2211</td>\n",
       "      <td>790</td>\n",
       "      <td>1119</td>\n",
       "      <td>61027</td>\n",
       "      <td>32048</td>\n",
       "      <td>1386</td>\n",
       "      <td>58</td>\n",
       "      <td>1572</td>\n",
       "      <td>147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>139441</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>13594</td>\n",
       "      <td>671</td>\n",
       "      <td>410</td>\n",
       "      <td>580</td>\n",
       "      <td>6228</td>\n",
       "      <td>3200</td>\n",
       "      <td>396</td>\n",
       "      <td>19</td>\n",
       "      <td>325</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>494</th>\n",
       "      <td>85093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>9218</td>\n",
       "      <td>810</td>\n",
       "      <td>756</td>\n",
       "      <td>1003</td>\n",
       "      <td>5654</td>\n",
       "      <td>3230</td>\n",
       "      <td>422</td>\n",
       "      <td>10</td>\n",
       "      <td>125</td>\n",
       "      <td>41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>85093</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7536</td>\n",
       "      <td>733</td>\n",
       "      <td>708</td>\n",
       "      <td>985</td>\n",
       "      <td>4750</td>\n",
       "      <td>2876</td>\n",
       "      <td>392</td>\n",
       "      <td>5</td>\n",
       "      <td>53</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>6229</td>\n",
       "      <td>537</td>\n",
       "      <td>508</td>\n",
       "      <td>687</td>\n",
       "      <td>3961</td>\n",
       "      <td>2104</td>\n",
       "      <td>301</td>\n",
       "      <td>0</td>\n",
       "      <td>53</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7216</td>\n",
       "      <td>625</td>\n",
       "      <td>572</td>\n",
       "      <td>795</td>\n",
       "      <td>4742</td>\n",
       "      <td>2388</td>\n",
       "      <td>363</td>\n",
       "      <td>4</td>\n",
       "      <td>93</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>81370</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>7564</td>\n",
       "      <td>626</td>\n",
       "      <td>574</td>\n",
       "      <td>832</td>\n",
       "      <td>4534</td>\n",
       "      <td>2452</td>\n",
       "      <td>370</td>\n",
       "      <td>7</td>\n",
       "      <td>91</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>495 rows Ã— 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Page total likes  Type_Link  Type_Photo  Type_Status  Type_Video  \\\n",
       "0              139441          0           1            0           0   \n",
       "1              139441          0           0            1           0   \n",
       "2              139441          0           1            0           0   \n",
       "3              139441          0           1            0           0   \n",
       "4              139441          0           1            0           0   \n",
       "..                ...        ...         ...          ...         ...   \n",
       "494             85093          0           1            0           0   \n",
       "495             85093          0           1            0           0   \n",
       "496             81370          0           1            0           0   \n",
       "497             81370          0           1            0           0   \n",
       "498             81370          0           1            0           0   \n",
       "\n",
       "     Category  Post Month  Post Weekday  Post Hour  Paid  ...  \\\n",
       "0           2          12             4          3     0  ...   \n",
       "1           2          12             3         10     0  ...   \n",
       "2           3          12             3          3     0  ...   \n",
       "3           2          12             2         10     1  ...   \n",
       "4           2          12             2          3     0  ...   \n",
       "..        ...         ...           ...        ...   ...  ...   \n",
       "494         3           1             7         10     0  ...   \n",
       "495         3           1             7          2     0  ...   \n",
       "496         2           1             5          8     0  ...   \n",
       "497         1           1             5          2     0  ...   \n",
       "498         3           1             4         11     0  ...   \n",
       "\n",
       "     Lifetime Post Total Impressions  Lifetime Engaged Users  \\\n",
       "0                               5091                     178   \n",
       "1                              19057                    1457   \n",
       "2                               4373                     177   \n",
       "3                              87991                    2211   \n",
       "4                              13594                     671   \n",
       "..                               ...                     ...   \n",
       "494                             9218                     810   \n",
       "495                             7536                     733   \n",
       "496                             6229                     537   \n",
       "497                             7216                     625   \n",
       "498                             7564                     626   \n",
       "\n",
       "     Lifetime Post Consumers  Lifetime Post Consumptions  \\\n",
       "0                        109                         159   \n",
       "1                       1361                        1674   \n",
       "2                        113                         154   \n",
       "3                        790                        1119   \n",
       "4                        410                         580   \n",
       "..                       ...                         ...   \n",
       "494                      756                        1003   \n",
       "495                      708                         985   \n",
       "496                      508                         687   \n",
       "497                      572                         795   \n",
       "498                      574                         832   \n",
       "\n",
       "     Lifetime Post Impressions by people who have liked your Page  \\\n",
       "0                                                 3078              \n",
       "1                                                11710              \n",
       "2                                                 2812              \n",
       "3                                                61027              \n",
       "4                                                 6228              \n",
       "..                                                 ...              \n",
       "494                                               5654              \n",
       "495                                               4750              \n",
       "496                                               3961              \n",
       "497                                               4742              \n",
       "498                                               4534              \n",
       "\n",
       "     Lifetime Post reach by people who like your Page  \\\n",
       "0                                                1640   \n",
       "1                                                6112   \n",
       "2                                                1503   \n",
       "3                                               32048   \n",
       "4                                                3200   \n",
       "..                                                ...   \n",
       "494                                              3230   \n",
       "495                                              2876   \n",
       "496                                              2104   \n",
       "497                                              2388   \n",
       "498                                              2452   \n",
       "\n",
       "     Lifetime People who have liked your Page and engaged with your post  \\\n",
       "0                                                  119                     \n",
       "1                                                 1108                     \n",
       "2                                                  132                     \n",
       "3                                                 1386                     \n",
       "4                                                  396                     \n",
       "..                                                 ...                     \n",
       "494                                                422                     \n",
       "495                                                392                     \n",
       "496                                                301                     \n",
       "497                                                363                     \n",
       "498                                                370                     \n",
       "\n",
       "     comment  like  share  \n",
       "0          4    79     17  \n",
       "1          5   130     29  \n",
       "2          0    66     14  \n",
       "3         58  1572    147  \n",
       "4         19   325     49  \n",
       "..       ...   ...    ...  \n",
       "494       10   125     41  \n",
       "495        5    53     26  \n",
       "496        0    53     22  \n",
       "497        4    93     18  \n",
       "498        7    91     38  \n",
       "\n",
       "[495 rows x 21 columns]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X2=fb_df.drop(\"Total Interactions\",axis=1)\n",
    "X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       100\n",
       "1       164\n",
       "2        80\n",
       "3      1777\n",
       "4       393\n",
       "       ... \n",
       "494     176\n",
       "495      84\n",
       "496      75\n",
       "497     115\n",
       "498     136\n",
       "Name: Total Interactions, Length: 495, dtype: int32"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y2=fb_df[\"Total Interactions\"]\n",
    "Y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train2, x_test2, y_train2, y_test2 = train_test_split(X2,Y2, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_fb_df = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_fb_df  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_fb_df  = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_fb_df= RandomForestRegressor(random_state=0)\n",
    "r_f_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_fb_df = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_fb_df.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_fb_df  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_fb_df.fit(x_train2,y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_fb_df  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_fb_df.fit(x_train2, y_train2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_15 (Dense)            (None, 128)               2816      \n",
      "                                                                 \n",
      " dense_16 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_17 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_18 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_19 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,681\n",
      "Trainable params: 167,681\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "10/10 [==============================] - 1s 29ms/step - loss: 538.5976 - mean_absolute_error: 538.5976 - val_loss: 263.7086 - val_mean_absolute_error: 263.7086\n",
      "Epoch 2/20\n",
      "10/10 [==============================] - 0s 9ms/step - loss: 171.6757 - mean_absolute_error: 171.6757 - val_loss: 120.2620 - val_mean_absolute_error: 120.2620\n",
      "Epoch 3/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 124.6360 - mean_absolute_error: 124.6360 - val_loss: 111.3268 - val_mean_absolute_error: 111.3268\n",
      "Epoch 4/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 123.9842 - mean_absolute_error: 123.9842 - val_loss: 124.7763 - val_mean_absolute_error: 124.7763\n",
      "Epoch 5/20\n",
      "10/10 [==============================] - 0s 6ms/step - loss: 119.9836 - mean_absolute_error: 119.9836 - val_loss: 161.4548 - val_mean_absolute_error: 161.4548\n",
      "Epoch 6/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 132.8781 - mean_absolute_error: 132.8781 - val_loss: 122.0108 - val_mean_absolute_error: 122.0108\n",
      "Epoch 7/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 126.7615 - mean_absolute_error: 126.7615 - val_loss: 124.7040 - val_mean_absolute_error: 124.7040\n",
      "Epoch 8/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 121.5303 - mean_absolute_error: 121.5303 - val_loss: 112.7639 - val_mean_absolute_error: 112.7639\n",
      "Epoch 9/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 114.3118 - mean_absolute_error: 114.3118 - val_loss: 114.3304 - val_mean_absolute_error: 114.3304\n",
      "Epoch 10/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 117.0002 - mean_absolute_error: 117.0002 - val_loss: 116.5473 - val_mean_absolute_error: 116.5473\n",
      "Epoch 11/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 109.5385 - mean_absolute_error: 109.5385 - val_loss: 116.6848 - val_mean_absolute_error: 116.6848\n",
      "Epoch 12/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 117.5745 - mean_absolute_error: 117.5745 - val_loss: 120.7078 - val_mean_absolute_error: 120.7078\n",
      "Epoch 13/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 116.2897 - mean_absolute_error: 116.2897 - val_loss: 147.2760 - val_mean_absolute_error: 147.2760\n",
      "Epoch 14/20\n",
      "10/10 [==============================] - 0s 7ms/step - loss: 114.1038 - mean_absolute_error: 114.1038 - val_loss: 118.1417 - val_mean_absolute_error: 118.1417\n",
      "Epoch 15/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 112.7813 - mean_absolute_error: 112.7813 - val_loss: 113.8755 - val_mean_absolute_error: 113.8755\n",
      "Epoch 16/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 108.3228 - mean_absolute_error: 108.3228 - val_loss: 109.7897 - val_mean_absolute_error: 109.7897\n",
      "Epoch 17/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 107.8075 - mean_absolute_error: 107.8075 - val_loss: 104.6026 - val_mean_absolute_error: 104.6026\n",
      "Epoch 18/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 104.2622 - mean_absolute_error: 104.2622 - val_loss: 106.2560 - val_mean_absolute_error: 106.2560\n",
      "Epoch 19/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 96.8784 - mean_absolute_error: 96.8784 - val_loss: 109.2439 - val_mean_absolute_error: 109.2439\n",
      "Epoch 20/20\n",
      "10/10 [==============================] - 0s 8ms/step - loss: 104.9399 - mean_absolute_error: 104.9399 - val_loss: 106.3934 - val_mean_absolute_error: 106.3934\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24554d9abb0>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model2 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model2.add(Dense(128, kernel_initializer='normal',input_dim = x_train2.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model2.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model2.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model2.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model2.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model2.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model2.summary()\n",
    "NN_model2.fit(x_train2, y_train2, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 6.244819608267731e-24\n",
      "R2: 1.0\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_fb_df.predict(x_test2)\n",
    "models_performances[\"Linear\"][\"facebook\"] = r2_score(y_test2, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 413683.26307991147\n",
      "R2: -0.024366534532081596\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_fb_df.predict(x_test2)\n",
    "models_performances[\"SVM\"][\"facebook\"] = r2_score(y_test2, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 174924.55555555556\n",
      "R2: 0.5668501078700992\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_fb_df.predict(x_test2)\n",
    "models_performances[\"DecisionTree\"][\"facebook\"] = r2_score(y_test2, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 192961.11743131306\n",
      "R2: 0.5221877972753045\n"
     ]
    }
   ],
   "source": [
    "output = r_f_fb_df.predict(x_test2)\n",
    "models_performances[\"RandomForest\"][\"facebook\"] = r2_score(y_test2, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 393127.0320391414\n",
      "R2: 0.02653500544684384\n"
     ]
    }
   ],
   "source": [
    "output = kn_fb_df.predict(x_test2)\n",
    "models_performances[\"KNN\"][\"facebook\"] = r2_score(y_test2, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 191132.78958485788\n",
      "R2: 0.526715120537353\n"
     ]
    }
   ],
   "source": [
    "output = ada_fb_df.predict(x_test2)\n",
    "models_performances[\"AdaBoost\"][\"facebook\"] = r2_score(y_test2, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 404742.402509948\n",
      "R2: -0.0022270883055157675\n"
     ]
    }
   ],
   "source": [
    "output = gpr_fb_df.predict(x_test2)\n",
    "models_performances[\"GaussianProcess\"][\"facebook\"] = r2_score(y_test2, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 448579.2098053142\n",
      "R2: -0.11077621847767505\n"
     ]
    }
   ],
   "source": [
    "output = NN_model2.predict(x_test2)\n",
    "models_performances[\"NeuralNetwork\"][\"facebook\"] = r2_score(y_test2, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test2, output)))\n",
    "print(f'R2: {r2_score(y_test2, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 5: Bike Sharing (use hour data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "bike=pd.read_csv('datasets/hour.csv')\n",
    "bike=bike.drop(['instant','dteday'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "      <th>cnt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "      <td>40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "      <td>119</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "      <td>89</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "      <td>61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "      <td>49</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows Ã— 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0           1   0     1   0        0        6           0           1  0.24   \n",
       "1           1   0     1   1        0        6           0           1  0.22   \n",
       "2           1   0     1   2        0        6           0           1  0.22   \n",
       "3           1   0     1   3        0        6           0           1  0.24   \n",
       "4           1   0     1   4        0        6           0           1  0.24   \n",
       "...       ...  ..   ...  ..      ...      ...         ...         ...   ...   \n",
       "17374       1   1    12  19        0        1           1           2  0.26   \n",
       "17375       1   1    12  20        0        1           1           2  0.26   \n",
       "17376       1   1    12  21        0        1           1           1  0.26   \n",
       "17377       1   1    12  22        0        1           1           1  0.26   \n",
       "17378       1   1    12  23        0        1           1           1  0.26   \n",
       "\n",
       "        atemp   hum  windspeed  casual  registered  cnt  \n",
       "0      0.2879  0.81     0.0000       3          13   16  \n",
       "1      0.2727  0.80     0.0000       8          32   40  \n",
       "2      0.2727  0.80     0.0000       5          27   32  \n",
       "3      0.2879  0.75     0.0000       3          10   13  \n",
       "4      0.2879  0.75     0.0000       0           1    1  \n",
       "...       ...   ...        ...     ...         ...  ...  \n",
       "17374  0.2576  0.60     0.1642      11         108  119  \n",
       "17375  0.2576  0.60     0.1642       8          81   89  \n",
       "17376  0.2576  0.60     0.1642       7          83   90  \n",
       "17377  0.2727  0.56     0.1343      13          48   61  \n",
       "17378  0.2727  0.65     0.1343      12          37   49  \n",
       "\n",
       "[17379 rows x 15 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bike"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>season</th>\n",
       "      <th>yr</th>\n",
       "      <th>mnth</th>\n",
       "      <th>hr</th>\n",
       "      <th>holiday</th>\n",
       "      <th>weekday</th>\n",
       "      <th>workingday</th>\n",
       "      <th>weathersit</th>\n",
       "      <th>temp</th>\n",
       "      <th>atemp</th>\n",
       "      <th>hum</th>\n",
       "      <th>windspeed</th>\n",
       "      <th>casual</th>\n",
       "      <th>registered</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.81</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>8</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.80</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>5</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.24</td>\n",
       "      <td>0.2879</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17374</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>19</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>11</td>\n",
       "      <td>108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17375</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>8</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17376</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>21</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2576</td>\n",
       "      <td>0.60</td>\n",
       "      <td>0.1642</td>\n",
       "      <td>7</td>\n",
       "      <td>83</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17377</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>22</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.56</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>13</td>\n",
       "      <td>48</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17378</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.26</td>\n",
       "      <td>0.2727</td>\n",
       "      <td>0.65</td>\n",
       "      <td>0.1343</td>\n",
       "      <td>12</td>\n",
       "      <td>37</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>17379 rows Ã— 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       season  yr  mnth  hr  holiday  weekday  workingday  weathersit  temp  \\\n",
       "0           1   0     1   0        0        6           0           1  0.24   \n",
       "1           1   0     1   1        0        6           0           1  0.22   \n",
       "2           1   0     1   2        0        6           0           1  0.22   \n",
       "3           1   0     1   3        0        6           0           1  0.24   \n",
       "4           1   0     1   4        0        6           0           1  0.24   \n",
       "...       ...  ..   ...  ..      ...      ...         ...         ...   ...   \n",
       "17374       1   1    12  19        0        1           1           2  0.26   \n",
       "17375       1   1    12  20        0        1           1           2  0.26   \n",
       "17376       1   1    12  21        0        1           1           1  0.26   \n",
       "17377       1   1    12  22        0        1           1           1  0.26   \n",
       "17378       1   1    12  23        0        1           1           1  0.26   \n",
       "\n",
       "        atemp   hum  windspeed  casual  registered  \n",
       "0      0.2879  0.81     0.0000       3          13  \n",
       "1      0.2727  0.80     0.0000       8          32  \n",
       "2      0.2727  0.80     0.0000       5          27  \n",
       "3      0.2879  0.75     0.0000       3          10  \n",
       "4      0.2879  0.75     0.0000       0           1  \n",
       "...       ...   ...        ...     ...         ...  \n",
       "17374  0.2576  0.60     0.1642      11         108  \n",
       "17375  0.2576  0.60     0.1642       8          81  \n",
       "17376  0.2576  0.60     0.1642       7          83  \n",
       "17377  0.2727  0.56     0.1343      13          48  \n",
       "17378  0.2727  0.65     0.1343      12          37  \n",
       "\n",
       "[17379 rows x 14 columns]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X3=bike.drop('cnt',axis=1)\n",
    "X3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0         16\n",
       "1         40\n",
       "2         32\n",
       "3         13\n",
       "4          1\n",
       "        ... \n",
       "17374    119\n",
       "17375     89\n",
       "17376     90\n",
       "17377     61\n",
       "17378     49\n",
       "Name: cnt, Length: 17379, dtype: int64"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y3=bike['cnt']\n",
    "Y3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train3, x_test3, y_train3, y_test3 = train_test_split(X3,Y3, train_size=0.8, random_state=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_bike = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=100)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_bike  = SVR(kernel=\"rbf\", C=100,max_iter=100, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_bike = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_bike= RandomForestRegressor(random_state=0)\n",
    "r_f_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_bike = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_bike.fit(x_train3,y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_bike  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_bike.fit(x_train3,y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_bike = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_bike.fit(x_train3, y_train3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_4\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_20 (Dense)            (None, 128)               1920      \n",
      "                                                                 \n",
      " dense_21 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_22 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_23 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_24 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,785\n",
      "Trainable params: 166,785\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "348/348 [==============================] - 3s 5ms/step - loss: 11.1815 - mean_absolute_error: 11.1815 - val_loss: 6.5059 - val_mean_absolute_error: 6.5059\n",
      "Epoch 2/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 4.0533 - mean_absolute_error: 4.0533 - val_loss: 3.9301 - val_mean_absolute_error: 3.9301\n",
      "Epoch 3/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 3.9228 - mean_absolute_error: 3.9228 - val_loss: 0.2432 - val_mean_absolute_error: 0.2432\n",
      "Epoch 4/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 4.3347 - mean_absolute_error: 4.3347 - val_loss: 1.9306 - val_mean_absolute_error: 1.9306\n",
      "Epoch 5/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 3.5493 - mean_absolute_error: 3.5493 - val_loss: 5.9386 - val_mean_absolute_error: 5.9386\n",
      "Epoch 6/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 3.7671 - mean_absolute_error: 3.7671 - val_loss: 0.7973 - val_mean_absolute_error: 0.7973\n",
      "Epoch 7/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 3.3742 - mean_absolute_error: 3.3742 - val_loss: 3.7117 - val_mean_absolute_error: 3.7117\n",
      "Epoch 8/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 3.1537 - mean_absolute_error: 3.1537 - val_loss: 6.4858 - val_mean_absolute_error: 6.4858\n",
      "Epoch 9/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.9709 - mean_absolute_error: 2.9709 - val_loss: 7.7410 - val_mean_absolute_error: 7.7410\n",
      "Epoch 10/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 3.3506 - mean_absolute_error: 3.3506 - val_loss: 0.7643 - val_mean_absolute_error: 0.7643\n",
      "Epoch 11/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.5694 - mean_absolute_error: 2.5694 - val_loss: 6.1119 - val_mean_absolute_error: 6.1119\n",
      "Epoch 12/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.6837 - mean_absolute_error: 2.6837 - val_loss: 6.1683 - val_mean_absolute_error: 6.1683\n",
      "Epoch 13/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.3758 - mean_absolute_error: 2.3758 - val_loss: 2.2092 - val_mean_absolute_error: 2.2092\n",
      "Epoch 14/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.3146 - mean_absolute_error: 2.3146 - val_loss: 4.1249 - val_mean_absolute_error: 4.1249\n",
      "Epoch 15/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.5703 - mean_absolute_error: 2.5703 - val_loss: 1.6940 - val_mean_absolute_error: 1.6940\n",
      "Epoch 16/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.5578 - mean_absolute_error: 2.5578 - val_loss: 2.9430 - val_mean_absolute_error: 2.9430\n",
      "Epoch 17/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.2500 - mean_absolute_error: 2.2500 - val_loss: 1.1611 - val_mean_absolute_error: 1.1611\n",
      "Epoch 18/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 1.9836 - mean_absolute_error: 1.9836 - val_loss: 2.2031 - val_mean_absolute_error: 2.2031\n",
      "Epoch 19/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.4181 - mean_absolute_error: 2.4181 - val_loss: 0.3679 - val_mean_absolute_error: 0.3679\n",
      "Epoch 20/20\n",
      "348/348 [==============================] - 1s 4ms/step - loss: 2.0061 - mean_absolute_error: 2.0061 - val_loss: 2.0985 - val_mean_absolute_error: 2.0985\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x2455c49cc10>"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model3 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model3.add(Dense(128, kernel_initializer='normal',input_dim = x_train3.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model3.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model3.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model3.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model3.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model3.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model3.summary()\n",
    "NN_model3.fit(x_train3, y_train3, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 3.0356217651947847e-26\n",
      "R2: 1.0\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_bike.predict(x_test3)\n",
    "models_performances[\"Linear\"][\"bike\"] = r2_score(y_test3, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 75243.41613615869\n",
      "R2: -1.254882593337776\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_bike.predict(x_test3)\n",
    "models_performances[\"SVM\"][\"bike\"] = r2_score(y_test3, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 33.5512082853855\n",
      "R2: 0.9989945427861586\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_bike.predict(x_test3)\n",
    "models_performances[\"DecisionTree\"][\"bike\"] = r2_score(y_test3, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 13.819550258918296\n",
      "R2: 0.9995858579404449\n"
     ]
    }
   ],
   "source": [
    "output = r_f_bike.predict(x_test3)\n",
    "models_performances[\"RandomForest\"][\"bike\"] = r2_score(y_test3, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 12.357545490506329\n",
      "R2: 0.9996296710642099\n"
     ]
    }
   ],
   "source": [
    "output = kn_bike.predict(x_test3)\n",
    "models_performances[\"KNN\"][\"bike\"] = r2_score(y_test3, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 785.1002319467559\n",
      "R2: 0.9764722425170239\n"
     ]
    }
   ],
   "source": [
    "output = ada_bike.predict(x_test3)\n",
    "models_performances[\"AdaBoost\"][\"bike\"] = r2_score(y_test3, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 27593.338544078943\n",
      "R2: 0.173087268359419\n"
     ]
    }
   ],
   "source": [
    "output = gpr_bike.predict(x_test3)\n",
    "models_performances[\"GaussianProcess\"][\"bike\"] = r2_score(y_test3, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output)))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 8.395548833652944\n",
      "R2: 0.9997484035428128\n"
     ]
    }
   ],
   "source": [
    "output = NN_model3.predict(x_test3)\n",
    "models_performances[\"NeuralNetwork\"][\"bike\"] = r2_score(y_test3, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test3, output.flatten())))\n",
    "print(f'R2: {r2_score(y_test3, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 6: Student Performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_GP</th>\n",
       "      <th>school_MS</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>age</th>\n",
       "      <th>address_R</th>\n",
       "      <th>address_U</th>\n",
       "      <th>famsize_GT3</th>\n",
       "      <th>famsize_LE3</th>\n",
       "      <th>Pstatus_A</th>\n",
       "      <th>...</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G2</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>13</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>12</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows Ã— 59 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school_GP  school_MS  sex_F  sex_M  age  address_R  address_U  \\\n",
       "0            1          0      1      0   18          0          1   \n",
       "1            1          0      1      0   17          0          1   \n",
       "2            1          0      1      0   15          0          1   \n",
       "3            1          0      1      0   15          0          1   \n",
       "4            1          0      1      0   16          0          1   \n",
       "..         ...        ...    ...    ...  ...        ...        ...   \n",
       "644          0          1      1      0   19          1          0   \n",
       "645          0          1      1      0   18          0          1   \n",
       "646          0          1      1      0   18          0          1   \n",
       "647          0          1      0      1   17          0          1   \n",
       "648          0          1      0      1   18          1          0   \n",
       "\n",
       "     famsize_GT3  famsize_LE3  Pstatus_A  ...  famrel  freetime  goout  Dalc  \\\n",
       "0              1            0          1  ...       4         3      4     1   \n",
       "1              1            0          0  ...       5         3      3     1   \n",
       "2              0            1          0  ...       4         3      2     2   \n",
       "3              1            0          0  ...       3         2      2     1   \n",
       "4              1            0          0  ...       4         3      2     1   \n",
       "..           ...          ...        ...  ...     ...       ...    ...   ...   \n",
       "644            1            0          0  ...       5         4      2     1   \n",
       "645            0            1          0  ...       4         3      4     1   \n",
       "646            1            0          0  ...       1         1      1     1   \n",
       "647            0            1          0  ...       2         4      5     3   \n",
       "648            0            1          0  ...       4         4      1     3   \n",
       "\n",
       "     Walc  health  absences  G1  G2  G3  \n",
       "0       1       3         4   0  11  11  \n",
       "1       1       3         2   9  11  11  \n",
       "2       3       3         6  12  13  12  \n",
       "3       1       5         0  14  14  14  \n",
       "4       2       5         0  11  13  13  \n",
       "..    ...     ...       ...  ..  ..  ..  \n",
       "644     2       5         4  10  11  10  \n",
       "645     1       1         4  15  15  16  \n",
       "646     1       5         6  11  12   9  \n",
       "647     4       2         6  10  10  10  \n",
       "648     4       5         4  10  11  11  \n",
       "\n",
       "[649 rows x 59 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#importing data\n",
    "stu=pd.read_csv('datasets/student-por.csv', sep=';')\n",
    "features_cat = ['school',\"sex\",'address','famsize','Pstatus','Mjob','Fjob','reason','guardian','schoolsup','famsup','paid','activities','nursery','higher','internet','romantic']\n",
    "\n",
    "# replace the columns with categorical values by its one hot encoding\n",
    "for feat in features_cat:\n",
    "    tmp_df = pd.get_dummies(stu[feat], prefix=feat)\n",
    "    idx = stu.columns.get_loc(feat)\n",
    "    for i, col in enumerate(tmp_df.columns):\n",
    "        stu.insert(idx+i, col, tmp_df[col])\n",
    "    stu = stu.drop(feat, axis=1)\n",
    "\n",
    "stu"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>school_GP</th>\n",
       "      <th>school_MS</th>\n",
       "      <th>sex_F</th>\n",
       "      <th>sex_M</th>\n",
       "      <th>age</th>\n",
       "      <th>address_R</th>\n",
       "      <th>address_U</th>\n",
       "      <th>famsize_GT3</th>\n",
       "      <th>famsize_LE3</th>\n",
       "      <th>Pstatus_A</th>\n",
       "      <th>...</th>\n",
       "      <th>romantic_yes</th>\n",
       "      <th>famrel</th>\n",
       "      <th>freetime</th>\n",
       "      <th>goout</th>\n",
       "      <th>Dalc</th>\n",
       "      <th>Walc</th>\n",
       "      <th>health</th>\n",
       "      <th>absences</th>\n",
       "      <th>G1</th>\n",
       "      <th>G3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>14</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>11</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>644</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>645</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>15</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>646</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>18</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>647</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>17</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>648</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>18</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>649 rows Ã— 58 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     school_GP  school_MS  sex_F  sex_M  age  address_R  address_U  \\\n",
       "0            1          0      1      0   18          0          1   \n",
       "1            1          0      1      0   17          0          1   \n",
       "2            1          0      1      0   15          0          1   \n",
       "3            1          0      1      0   15          0          1   \n",
       "4            1          0      1      0   16          0          1   \n",
       "..         ...        ...    ...    ...  ...        ...        ...   \n",
       "644          0          1      1      0   19          1          0   \n",
       "645          0          1      1      0   18          0          1   \n",
       "646          0          1      1      0   18          0          1   \n",
       "647          0          1      0      1   17          0          1   \n",
       "648          0          1      0      1   18          1          0   \n",
       "\n",
       "     famsize_GT3  famsize_LE3  Pstatus_A  ...  romantic_yes  famrel  freetime  \\\n",
       "0              1            0          1  ...             0       4         3   \n",
       "1              1            0          0  ...             0       5         3   \n",
       "2              0            1          0  ...             0       4         3   \n",
       "3              1            0          0  ...             1       3         2   \n",
       "4              1            0          0  ...             0       4         3   \n",
       "..           ...          ...        ...  ...           ...     ...       ...   \n",
       "644            1            0          0  ...             0       5         4   \n",
       "645            0            1          0  ...             0       4         3   \n",
       "646            1            0          0  ...             0       1         1   \n",
       "647            0            1          0  ...             0       2         4   \n",
       "648            0            1          0  ...             0       4         4   \n",
       "\n",
       "     goout  Dalc  Walc  health  absences  G1  G3  \n",
       "0        4     1     1       3         4   0  11  \n",
       "1        3     1     1       3         2   9  11  \n",
       "2        2     2     3       3         6  12  12  \n",
       "3        2     1     1       5         0  14  14  \n",
       "4        2     1     2       5         0  11  13  \n",
       "..     ...   ...   ...     ...       ...  ..  ..  \n",
       "644      2     1     2       5         4  10  10  \n",
       "645      4     1     1       1         4  15  16  \n",
       "646      1     1     1       5         6  11   9  \n",
       "647      5     3     4       2         6  10  10  \n",
       "648      1     3     4       5         4  10  11  \n",
       "\n",
       "[649 rows x 58 columns]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X4=stu.drop(\"G2\",axis=1)\n",
    "X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      11\n",
       "1      11\n",
       "2      13\n",
       "3      14\n",
       "4      13\n",
       "       ..\n",
       "644    11\n",
       "645    15\n",
       "646    12\n",
       "647    10\n",
       "648    11\n",
       "Name: G2, Length: 649, dtype: int64"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y4=stu[\"G2\"]\n",
    "Y4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train4, x_test4, y_train4, y_test4 = train_test_split(X4,Y4, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_stu = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_stu.fit(x_train4, y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_stu  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_stu.fit(x_train4, y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_stu = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_stu.fit(x_train4, y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_stu= RandomForestRegressor(random_state=0)\n",
    "r_f_stu.fit(x_train4, y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_stu = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_stu.fit(x_train4,y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_stu  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_stu.fit(x_train4,y_train4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_stu  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_stu.fit(x_train4, y_train4)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_25 (Dense)            (None, 128)               7552      \n",
      "                                                                 \n",
      " dense_26 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_27 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_28 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_29 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 172,417\n",
      "Trainable params: 172,417\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "13/13 [==============================] - 1s 23ms/step - loss: 7.3823 - mean_absolute_error: 7.3823 - val_loss: 3.7100 - val_mean_absolute_error: 3.7100\n",
      "Epoch 2/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 2.2716 - mean_absolute_error: 2.2716 - val_loss: 2.1022 - val_mean_absolute_error: 2.1022\n",
      "Epoch 3/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.4908 - mean_absolute_error: 1.4908 - val_loss: 1.1131 - val_mean_absolute_error: 1.1131\n",
      "Epoch 4/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 1.0151 - mean_absolute_error: 1.0151 - val_loss: 0.7851 - val_mean_absolute_error: 0.7851\n",
      "Epoch 5/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8287 - mean_absolute_error: 0.8287 - val_loss: 0.9803 - val_mean_absolute_error: 0.9803\n",
      "Epoch 6/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.9173 - mean_absolute_error: 0.9173 - val_loss: 0.7983 - val_mean_absolute_error: 0.7983\n",
      "Epoch 7/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8405 - mean_absolute_error: 0.8405 - val_loss: 0.7241 - val_mean_absolute_error: 0.7241\n",
      "Epoch 8/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8347 - mean_absolute_error: 0.8347 - val_loss: 0.7031 - val_mean_absolute_error: 0.7031\n",
      "Epoch 9/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7901 - mean_absolute_error: 0.7901 - val_loss: 0.9843 - val_mean_absolute_error: 0.9843\n",
      "Epoch 10/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7692 - mean_absolute_error: 0.7692 - val_loss: 0.6921 - val_mean_absolute_error: 0.6921\n",
      "Epoch 11/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7986 - mean_absolute_error: 0.7986 - val_loss: 0.6973 - val_mean_absolute_error: 0.6973\n",
      "Epoch 12/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8098 - mean_absolute_error: 0.8098 - val_loss: 0.7077 - val_mean_absolute_error: 0.7077\n",
      "Epoch 13/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7655 - mean_absolute_error: 0.7655 - val_loss: 0.9380 - val_mean_absolute_error: 0.9380\n",
      "Epoch 14/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8547 - mean_absolute_error: 0.8547 - val_loss: 0.7174 - val_mean_absolute_error: 0.7174\n",
      "Epoch 15/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7957 - mean_absolute_error: 0.7957 - val_loss: 0.7172 - val_mean_absolute_error: 0.7172\n",
      "Epoch 16/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7557 - mean_absolute_error: 0.7557 - val_loss: 0.7297 - val_mean_absolute_error: 0.7297\n",
      "Epoch 17/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.7226 - mean_absolute_error: 0.7226 - val_loss: 0.7682 - val_mean_absolute_error: 0.7682\n",
      "Epoch 18/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.7359 - mean_absolute_error: 0.7359 - val_loss: 0.7241 - val_mean_absolute_error: 0.7241\n",
      "Epoch 19/20\n",
      "13/13 [==============================] - 0s 6ms/step - loss: 0.8022 - mean_absolute_error: 0.8022 - val_loss: 0.8621 - val_mean_absolute_error: 0.8621\n",
      "Epoch 20/20\n",
      "13/13 [==============================] - 0s 7ms/step - loss: 0.8432 - mean_absolute_error: 0.8432 - val_loss: 0.8908 - val_mean_absolute_error: 0.8908\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24554df9940>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model4 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model4.add(Dense(128, kernel_initializer='normal',input_dim = x_train4.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model4.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model4.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model4.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model4.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model4.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model4.summary()\n",
    "NN_model4.fit(x_train4, y_train4, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.8929838628855508\n",
      "R2: 0.8559208424084834\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_stu.predict(x_test4)\n",
    "models_performances[\"Linear\"][\"student\"] = r2_score(y_test4, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 2.722224482852483\n",
      "R2: 0.5607806293419483\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_stu.predict(x_test4)\n",
    "models_performances[\"SVM\"][\"student\"] = r2_score(y_test4, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.5307692307692307\n",
      "R2: 0.7530168792484533\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_stu.predict(x_test4)\n",
    "models_performances[\"DecisionTree\"][\"student\"] = r2_score(y_test4, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7516376923076923\n",
      "R2: 0.8787264473382723\n"
     ]
    }
   ],
   "source": [
    "output = r_f_stu.predict(x_test4)\n",
    "models_performances[\"RandomForest\"][\"student\"] = r2_score(y_test4, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.9050480769230769\n",
      "R2: 0.8539743326586726\n"
     ]
    }
   ],
   "source": [
    "output = kn_stu.predict(x_test4)\n",
    "models_performances[\"KNN\"][\"student\"] = r2_score(y_test4, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.869359694727863\n",
      "R2: 0.8597325017098747\n"
     ]
    }
   ],
   "source": [
    "output = ada_stu.predict(x_test4)\n",
    "models_performances[\"AdaBoost\"][\"student\"] = r2_score(y_test4, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 6.5471967055419045\n",
      "R2: -0.0563624104832563\n"
     ]
    }
   ],
   "source": [
    "output = gpr_stu.predict(x_test4)\n",
    "models_performances[\"GaussianProcess\"][\"student\"] = r2_score(y_test4, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output)))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.2576376027331644\n",
      "R2: 0.7970855086096532\n"
     ]
    }
   ],
   "source": [
    "output = NN_model4.predict(x_test4)\n",
    "models_performances[\"NeuralNetwork\"][\"student\"] = r2_score(y_test4, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test4, output.flatten())))\n",
    "print(f'R2: {r2_score(y_test4, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 7: Concrete Compressive Strength"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing data\n",
    "con=pd.read_excel('datasets/Concrete_Data.xls')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "      <th>Concrete compressive strength(MPa, megapascals)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>79.986111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "      <td>61.887366</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "      <td>40.269535</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "      <td>41.052780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "      <td>44.296075</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "      <td>44.284354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "      <td>31.178794</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "      <td>23.696601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "      <td>32.768036</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "      <td>32.401235</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                         540.0   \n",
       "1                                         540.0   \n",
       "2                                         332.5   \n",
       "3                                         332.5   \n",
       "4                                         198.6   \n",
       "...                                         ...   \n",
       "1025                                      276.4   \n",
       "1026                                      322.2   \n",
       "1027                                      148.5   \n",
       "1028                                      159.1   \n",
       "1029                                      260.9   \n",
       "\n",
       "      Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                   0.0       \n",
       "1                                                   0.0       \n",
       "2                                                 142.5       \n",
       "3                                                 142.5       \n",
       "4                                                 132.4       \n",
       "...                                                 ...       \n",
       "1025                                              116.0       \n",
       "1026                                                0.0       \n",
       "1027                                              139.4       \n",
       "1028                                              186.7       \n",
       "1029                                              100.5       \n",
       "\n",
       "      Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "1025                                        90.3   \n",
       "1026                                       115.6   \n",
       "1027                                       108.6   \n",
       "1028                                         0.0   \n",
       "1029                                        78.3   \n",
       "\n",
       "      Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                         162.0   \n",
       "1                                         162.0   \n",
       "2                                         228.0   \n",
       "3                                         228.0   \n",
       "4                                         192.0   \n",
       "...                                         ...   \n",
       "1025                                      179.6   \n",
       "1026                                      196.0   \n",
       "1027                                      192.7   \n",
       "1028                                      175.6   \n",
       "1029                                      200.6   \n",
       "\n",
       "      Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                   2.5     \n",
       "1                                                   2.5     \n",
       "2                                                   0.0     \n",
       "3                                                   0.0     \n",
       "4                                                   0.0     \n",
       "...                                                 ...     \n",
       "1025                                                8.9     \n",
       "1026                                               10.4     \n",
       "1027                                                6.1     \n",
       "1028                                               11.3     \n",
       "1029                                                8.6     \n",
       "\n",
       "      Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                                1040.0      \n",
       "1                                                1055.0      \n",
       "2                                                 932.0      \n",
       "3                                                 932.0      \n",
       "4                                                 978.4      \n",
       "...                                                 ...      \n",
       "1025                                              870.1      \n",
       "1026                                              817.9      \n",
       "1027                                              892.4      \n",
       "1028                                              989.6      \n",
       "1029                                              864.5      \n",
       "\n",
       "      Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \\\n",
       "0                                                 676.0         28   \n",
       "1                                                 676.0         28   \n",
       "2                                                 594.0        270   \n",
       "3                                                 594.0        365   \n",
       "4                                                 825.5        360   \n",
       "...                                                 ...        ...   \n",
       "1025                                              768.3         28   \n",
       "1026                                              813.4         28   \n",
       "1027                                              780.0         28   \n",
       "1028                                              788.9         28   \n",
       "1029                                              761.5         28   \n",
       "\n",
       "      Concrete compressive strength(MPa, megapascals)   \n",
       "0                                            79.986111  \n",
       "1                                            61.887366  \n",
       "2                                            40.269535  \n",
       "3                                            41.052780  \n",
       "4                                            44.296075  \n",
       "...                                                ...  \n",
       "1025                                         44.284354  \n",
       "1026                                         31.178794  \n",
       "1027                                         23.696601  \n",
       "1028                                         32.768036  \n",
       "1029                                         32.401235  \n",
       "\n",
       "[1030 rows x 9 columns]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "con"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cement (component 1)(kg in a m^3 mixture)</th>\n",
       "      <th>Blast Furnace Slag (component 2)(kg in a m^3 mixture)</th>\n",
       "      <th>Fly Ash (component 3)(kg in a m^3 mixture)</th>\n",
       "      <th>Water  (component 4)(kg in a m^3 mixture)</th>\n",
       "      <th>Superplasticizer (component 5)(kg in a m^3 mixture)</th>\n",
       "      <th>Coarse Aggregate  (component 6)(kg in a m^3 mixture)</th>\n",
       "      <th>Fine Aggregate (component 7)(kg in a m^3 mixture)</th>\n",
       "      <th>Age (day)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1040.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>540.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>162.0</td>\n",
       "      <td>2.5</td>\n",
       "      <td>1055.0</td>\n",
       "      <td>676.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>270</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>332.5</td>\n",
       "      <td>142.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>228.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>932.0</td>\n",
       "      <td>594.0</td>\n",
       "      <td>365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>198.6</td>\n",
       "      <td>132.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>192.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>978.4</td>\n",
       "      <td>825.5</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>276.4</td>\n",
       "      <td>116.0</td>\n",
       "      <td>90.3</td>\n",
       "      <td>179.6</td>\n",
       "      <td>8.9</td>\n",
       "      <td>870.1</td>\n",
       "      <td>768.3</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1026</th>\n",
       "      <td>322.2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>115.6</td>\n",
       "      <td>196.0</td>\n",
       "      <td>10.4</td>\n",
       "      <td>817.9</td>\n",
       "      <td>813.4</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1027</th>\n",
       "      <td>148.5</td>\n",
       "      <td>139.4</td>\n",
       "      <td>108.6</td>\n",
       "      <td>192.7</td>\n",
       "      <td>6.1</td>\n",
       "      <td>892.4</td>\n",
       "      <td>780.0</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1028</th>\n",
       "      <td>159.1</td>\n",
       "      <td>186.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>175.6</td>\n",
       "      <td>11.3</td>\n",
       "      <td>989.6</td>\n",
       "      <td>788.9</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1029</th>\n",
       "      <td>260.9</td>\n",
       "      <td>100.5</td>\n",
       "      <td>78.3</td>\n",
       "      <td>200.6</td>\n",
       "      <td>8.6</td>\n",
       "      <td>864.5</td>\n",
       "      <td>761.5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1030 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Cement (component 1)(kg in a m^3 mixture)  \\\n",
       "0                                         540.0   \n",
       "1                                         540.0   \n",
       "2                                         332.5   \n",
       "3                                         332.5   \n",
       "4                                         198.6   \n",
       "...                                         ...   \n",
       "1025                                      276.4   \n",
       "1026                                      322.2   \n",
       "1027                                      148.5   \n",
       "1028                                      159.1   \n",
       "1029                                      260.9   \n",
       "\n",
       "      Blast Furnace Slag (component 2)(kg in a m^3 mixture)  \\\n",
       "0                                                   0.0       \n",
       "1                                                   0.0       \n",
       "2                                                 142.5       \n",
       "3                                                 142.5       \n",
       "4                                                 132.4       \n",
       "...                                                 ...       \n",
       "1025                                              116.0       \n",
       "1026                                                0.0       \n",
       "1027                                              139.4       \n",
       "1028                                              186.7       \n",
       "1029                                              100.5       \n",
       "\n",
       "      Fly Ash (component 3)(kg in a m^3 mixture)  \\\n",
       "0                                            0.0   \n",
       "1                                            0.0   \n",
       "2                                            0.0   \n",
       "3                                            0.0   \n",
       "4                                            0.0   \n",
       "...                                          ...   \n",
       "1025                                        90.3   \n",
       "1026                                       115.6   \n",
       "1027                                       108.6   \n",
       "1028                                         0.0   \n",
       "1029                                        78.3   \n",
       "\n",
       "      Water  (component 4)(kg in a m^3 mixture)  \\\n",
       "0                                         162.0   \n",
       "1                                         162.0   \n",
       "2                                         228.0   \n",
       "3                                         228.0   \n",
       "4                                         192.0   \n",
       "...                                         ...   \n",
       "1025                                      179.6   \n",
       "1026                                      196.0   \n",
       "1027                                      192.7   \n",
       "1028                                      175.6   \n",
       "1029                                      200.6   \n",
       "\n",
       "      Superplasticizer (component 5)(kg in a m^3 mixture)  \\\n",
       "0                                                   2.5     \n",
       "1                                                   2.5     \n",
       "2                                                   0.0     \n",
       "3                                                   0.0     \n",
       "4                                                   0.0     \n",
       "...                                                 ...     \n",
       "1025                                                8.9     \n",
       "1026                                               10.4     \n",
       "1027                                                6.1     \n",
       "1028                                               11.3     \n",
       "1029                                                8.6     \n",
       "\n",
       "      Coarse Aggregate  (component 6)(kg in a m^3 mixture)  \\\n",
       "0                                                1040.0      \n",
       "1                                                1055.0      \n",
       "2                                                 932.0      \n",
       "3                                                 932.0      \n",
       "4                                                 978.4      \n",
       "...                                                 ...      \n",
       "1025                                              870.1      \n",
       "1026                                              817.9      \n",
       "1027                                              892.4      \n",
       "1028                                              989.6      \n",
       "1029                                              864.5      \n",
       "\n",
       "      Fine Aggregate (component 7)(kg in a m^3 mixture)  Age (day)  \n",
       "0                                                 676.0         28  \n",
       "1                                                 676.0         28  \n",
       "2                                                 594.0        270  \n",
       "3                                                 594.0        365  \n",
       "4                                                 825.5        360  \n",
       "...                                                 ...        ...  \n",
       "1025                                              768.3         28  \n",
       "1026                                              813.4         28  \n",
       "1027                                              780.0         28  \n",
       "1028                                              788.9         28  \n",
       "1029                                              761.5         28  \n",
       "\n",
       "[1030 rows x 8 columns]"
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X5=con.drop(['Concrete compressive strength(MPa, megapascals) '],axis=1)\n",
    "X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       79.986111\n",
       "1       61.887366\n",
       "2       40.269535\n",
       "3       41.052780\n",
       "4       44.296075\n",
       "          ...    \n",
       "1025    44.284354\n",
       "1026    31.178794\n",
       "1027    23.696601\n",
       "1028    32.768036\n",
       "1029    32.401235\n",
       "Name: Concrete compressive strength(MPa, megapascals) , Length: 1030, dtype: float64"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y5=con['Concrete compressive strength(MPa, megapascals) ']\n",
    "Y5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train5, x_test5, y_train5, y_test5 = train_test_split(X5,Y5, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_con = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=10000)"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_con  = SVR(kernel=\"rbf\", C=100,max_iter=10000, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_con = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 133,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_con= RandomForestRegressor(random_state=0)\n",
    "r_f_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_con = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_con.fit(x_train5,y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_con  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_con.fit(x_train5,y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_con  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_con.fit(x_train5, y_train5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_6\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_30 (Dense)            (None, 128)               1152      \n",
      "                                                                 \n",
      " dense_31 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_32 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_33 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_34 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 166,017\n",
      "Trainable params: 166,017\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "21/21 [==============================] - 1s 16ms/step - loss: 14.2259 - mean_absolute_error: 14.2259 - val_loss: 11.8713 - val_mean_absolute_error: 11.8713\n",
      "Epoch 2/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 10.5073 - mean_absolute_error: 10.5073 - val_loss: 10.0931 - val_mean_absolute_error: 10.0931\n",
      "Epoch 3/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 9.2378 - mean_absolute_error: 9.2378 - val_loss: 8.8059 - val_mean_absolute_error: 8.8059\n",
      "Epoch 4/20\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 8.4693 - mean_absolute_error: 8.4693 - val_loss: 7.6113 - val_mean_absolute_error: 7.6113\n",
      "Epoch 5/20\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 8.5260 - mean_absolute_error: 8.5260 - val_loss: 8.2994 - val_mean_absolute_error: 8.2994\n",
      "Epoch 6/20\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 8.6070 - mean_absolute_error: 8.6070 - val_loss: 7.5093 - val_mean_absolute_error: 7.5093\n",
      "Epoch 7/20\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 7.6213 - mean_absolute_error: 7.6213 - val_loss: 6.4496 - val_mean_absolute_error: 6.4496\n",
      "Epoch 8/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 7.0223 - mean_absolute_error: 7.0223 - val_loss: 6.7497 - val_mean_absolute_error: 6.7497\n",
      "Epoch 9/20\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.3110 - mean_absolute_error: 6.3110 - val_loss: 5.8098 - val_mean_absolute_error: 5.8098\n",
      "Epoch 10/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.0420 - mean_absolute_error: 6.0420 - val_loss: 7.7693 - val_mean_absolute_error: 7.7693\n",
      "Epoch 11/20\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 6.3391 - mean_absolute_error: 6.3391 - val_loss: 5.8175 - val_mean_absolute_error: 5.8175\n",
      "Epoch 12/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.6366 - mean_absolute_error: 5.6366 - val_loss: 5.5661 - val_mean_absolute_error: 5.5661\n",
      "Epoch 13/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.6574 - mean_absolute_error: 5.6574 - val_loss: 5.9657 - val_mean_absolute_error: 5.9657\n",
      "Epoch 14/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.1160 - mean_absolute_error: 6.1160 - val_loss: 5.6821 - val_mean_absolute_error: 5.6821\n",
      "Epoch 15/20\n",
      "21/21 [==============================] - 0s 7ms/step - loss: 5.4578 - mean_absolute_error: 5.4578 - val_loss: 5.2069 - val_mean_absolute_error: 5.2069\n",
      "Epoch 16/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.3349 - mean_absolute_error: 5.3349 - val_loss: 5.9246 - val_mean_absolute_error: 5.9246\n",
      "Epoch 17/20\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 6.1826 - mean_absolute_error: 6.1826 - val_loss: 6.2945 - val_mean_absolute_error: 6.2945\n",
      "Epoch 18/20\n",
      "21/21 [==============================] - 0s 5ms/step - loss: 5.5636 - mean_absolute_error: 5.5636 - val_loss: 5.1474 - val_mean_absolute_error: 5.1474\n",
      "Epoch 19/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 5.8054 - mean_absolute_error: 5.8054 - val_loss: 7.5052 - val_mean_absolute_error: 7.5052\n",
      "Epoch 20/20\n",
      "21/21 [==============================] - 0s 6ms/step - loss: 6.6168 - mean_absolute_error: 6.6168 - val_loss: 5.2386 - val_mean_absolute_error: 5.2386\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x24557cd30d0>"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model5 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model5.add(Dense(128, kernel_initializer='normal',input_dim = x_train5.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model5.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model5.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model5.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model5.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model5.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model5.summary()\n",
    "NN_model5.fit(x_train5, y_train5, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 112.50624757466328\n",
      "R2: 0.6253216399803967\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_con.predict(x_test5)\n",
    "models_performances[\"Linear\"][\"concrete\"] = r2_score(y_test5, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 229.04510714982916\n",
      "R2: 0.23721351509426025\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_con.predict(x_test5)\n",
    "models_performances[\"SVM\"][\"concrete\"] = r2_score(y_test5, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 38.523821112087056\n",
      "R2: 0.8717045281739897\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_con.predict(x_test5)\n",
    "models_performances[\"DecisionTree\"][\"concrete\"] = r2_score(y_test5, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 21.46375290198892\n",
      "R2: 0.9285194919344703\n"
     ]
    }
   ],
   "source": [
    "output = r_f_con.predict(x_test5)\n",
    "models_performances[\"RandomForest\"][\"concrete\"] = r2_score(y_test5, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 98.5056087585407\n",
      "R2: 0.6719478185610159\n"
     ]
    }
   ],
   "source": [
    "output = kn_con.predict(x_test5)\n",
    "models_performances[\"KNN\"][\"concrete\"] = r2_score(y_test5, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 55.081810221783336\n",
      "R2: 0.8165616331029732\n"
     ]
    }
   ],
   "source": [
    "output = ada_con.predict(x_test5)\n",
    "models_performances[\"AdaBoost\"][\"concrete\"] = r2_score(y_test5, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 246.1226546100533\n",
      "R2: 0.1803403403729419\n"
     ]
    }
   ],
   "source": [
    "output = gpr_con.predict(x_test5)\n",
    "models_performances[\"GaussianProcess\"][\"concrete\"] = r2_score(y_test5, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output)))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 54.77429982553594\n",
      "R2: 0.8175857317058397\n"
     ]
    }
   ],
   "source": [
    "output = NN_model5.predict(x_test5)\n",
    "models_performances[\"NeuralNetwork\"][\"concrete\"] = r2_score(y_test5, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test5, output.flatten())))\n",
    "print(f'R2: {r2_score(y_test5, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataset 8: SGEMM GPU kernel performance "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Required Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "sge=pd.read_csv('datasets/sgemm_product.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data analysis and visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "sge=sge.iloc[-10000:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MWG</th>\n",
       "      <th>NWG</th>\n",
       "      <th>KWG</th>\n",
       "      <th>MDIMC</th>\n",
       "      <th>NDIMC</th>\n",
       "      <th>MDIMA</th>\n",
       "      <th>NDIMB</th>\n",
       "      <th>KWI</th>\n",
       "      <th>VWM</th>\n",
       "      <th>VWN</th>\n",
       "      <th>STRM</th>\n",
       "      <th>STRN</th>\n",
       "      <th>SA</th>\n",
       "      <th>SB</th>\n",
       "      <th>Run1 (ms)</th>\n",
       "      <th>Run2 (ms)</th>\n",
       "      <th>Run3 (ms)</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>231600</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>276.01</td>\n",
       "      <td>278.68</td>\n",
       "      <td>278.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231601</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>200.92</td>\n",
       "      <td>202.71</td>\n",
       "      <td>203.07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231602</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>179.35</td>\n",
       "      <td>176.94</td>\n",
       "      <td>176.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231603</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>189.54</td>\n",
       "      <td>189.66</td>\n",
       "      <td>189.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>231604</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "      <td>8</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>289.42</td>\n",
       "      <td>291.90</td>\n",
       "      <td>291.96</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241595</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.96</td>\n",
       "      <td>17.77</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241596</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>36.04</td>\n",
       "      <td>36.03</td>\n",
       "      <td>36.04</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241597</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>35.28</td>\n",
       "      <td>34.82</td>\n",
       "      <td>35.27</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241598</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>28.43</td>\n",
       "      <td>28.49</td>\n",
       "      <td>28.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>241599</th>\n",
       "      <td>128</td>\n",
       "      <td>128</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>32</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>17.94</td>\n",
       "      <td>17.79</td>\n",
       "      <td>17.77</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows Ã— 17 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        MWG  NWG  KWG  MDIMC  NDIMC  MDIMA  NDIMB  KWI  VWM  VWN  STRM  STRN  \\\n",
       "231600  128  128   32     16     16      8      8    2    1    2     0     0   \n",
       "231601  128  128   32     16     16      8      8    2    1    2     0     0   \n",
       "231602  128  128   32     16     16      8      8    2    1    2     0     0   \n",
       "231603  128  128   32     16     16      8      8    2    1    2     0     0   \n",
       "231604  128  128   32     16     16      8      8    2    1    2     0     1   \n",
       "...     ...  ...  ...    ...    ...    ...    ...  ...  ...  ...   ...   ...   \n",
       "241595  128  128   32     32     32     32     32    8    4    4     1     0   \n",
       "241596  128  128   32     32     32     32     32    8    4    4     1     1   \n",
       "241597  128  128   32     32     32     32     32    8    4    4     1     1   \n",
       "241598  128  128   32     32     32     32     32    8    4    4     1     1   \n",
       "241599  128  128   32     32     32     32     32    8    4    4     1     1   \n",
       "\n",
       "        SA  SB  Run1 (ms)  Run2 (ms)  Run3 (ms)  \n",
       "231600   0   0     276.01     278.68     278.95  \n",
       "231601   0   1     200.92     202.71     203.07  \n",
       "231602   1   0     179.35     176.94     176.29  \n",
       "231603   1   1     189.54     189.66     189.64  \n",
       "231604   0   0     289.42     291.90     291.96  \n",
       "...     ..  ..        ...        ...        ...  \n",
       "241595   1   1      17.96      17.77      17.77  \n",
       "241596   0   0      36.04      36.03      36.04  \n",
       "241597   0   1      35.28      34.82      35.27  \n",
       "241598   1   0      28.43      28.49      28.44  \n",
       "241599   1   1      17.94      17.79      17.77  \n",
       "\n",
       "[10000 rows x 17 columns]"
      ]
     },
     "execution_count": 148,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X6=sge.drop('Run4 (ms)',axis=1)\n",
    "X6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231600    279.37\n",
       "231601    204.25\n",
       "231602    175.75\n",
       "231603    189.67\n",
       "231604    292.51\n",
       "           ...  \n",
       "241595     17.77\n",
       "241596     36.03\n",
       "241597     35.27\n",
       "241598     28.45\n",
       "241599     17.77\n",
       "Name: Run4 (ms), Length: 10000, dtype: float64"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y6=sge['Run4 (ms)']\n",
    "Y6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Splitting into Training and Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's say we want to split the data in 80:10:10 for train:valid:test dataset\n",
    "train_size=0.8\n",
    "\n",
    "\n",
    "# In the first step we will split the data in training and remaining dataset\n",
    "x_train6, x_test6, y_train6, y_test6 = train_test_split(X6,Y6, train_size=0.8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression()"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create linear regression object\n",
    "l_reg_sge = linear_model.LinearRegression()\n",
    " \n",
    "# train the model using the training sets\n",
    "l_reg_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Sam\\anaconda3\\lib\\site-packages\\sklearn\\svm\\_base.py:255: ConvergenceWarning: Solver terminated early (max_iter=100).  Consider pre-processing your data with StandardScaler or MinMaxScaler.\n",
      "  warnings.warn('Solver terminated early (max_iter=%i).'\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SVR(C=100, gamma=0.1, max_iter=100)"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "svr_rbf_sge  = SVR(kernel=\"rbf\", C=100,max_iter=100, gamma=0.1, epsilon=0.1)\n",
    "svr_rbf_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeRegressor(max_depth=100, random_state=0)"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dr_regr_sge = DecisionTreeRegressor(max_depth=100, random_state=0)\n",
    "dr_regr_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(random_state=0)"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r_f_sge= RandomForestRegressor(random_state=0)\n",
    "r_f_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsRegressor(n_neighbors=8)"
      ]
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kn_sge = KNeighborsRegressor(n_neighbors=8)\n",
    "kn_sge.fit(x_train6,y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AdaBoostRegressor(n_estimators=100, random_state=0)"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ada_sge  = AdaBoostRegressor(random_state=0, n_estimators=100)\n",
    "ada_sge.fit(x_train6,y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianProcessRegressor(alpha=0.1, n_restarts_optimizer=10, normalize_y=True,\n",
       "                         random_state=0)"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gpr_sge  = gp.GaussianProcessRegressor(n_restarts_optimizer=10, alpha=0.1, normalize_y=True, random_state=0)\n",
    "gpr_sge.fit(x_train6, y_train6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " dense_35 (Dense)            (None, 128)               2304      \n",
      "                                                                 \n",
      " dense_36 (Dense)            (None, 256)               33024     \n",
      "                                                                 \n",
      " dense_37 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_38 (Dense)            (None, 256)               65792     \n",
      "                                                                 \n",
      " dense_39 (Dense)            (None, 1)                 257       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 167,169\n",
      "Trainable params: 167,169\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "200/200 [==============================] - 2s 5ms/step - loss: 12.4538 - mean_absolute_error: 12.4538 - val_loss: 3.7658 - val_mean_absolute_error: 3.7658\n",
      "Epoch 2/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 3.7222 - mean_absolute_error: 3.7222 - val_loss: 3.3026 - val_mean_absolute_error: 3.3026\n",
      "Epoch 3/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 3.9696 - mean_absolute_error: 3.9696 - val_loss: 1.2624 - val_mean_absolute_error: 1.2624\n",
      "Epoch 4/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.2121 - mean_absolute_error: 2.2121 - val_loss: 0.6368 - val_mean_absolute_error: 0.6368\n",
      "Epoch 5/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 4.1780 - mean_absolute_error: 4.1780 - val_loss: 1.5424 - val_mean_absolute_error: 1.5424\n",
      "Epoch 6/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 3.0159 - mean_absolute_error: 3.0159 - val_loss: 1.1083 - val_mean_absolute_error: 1.1083\n",
      "Epoch 7/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.9806 - mean_absolute_error: 2.9806 - val_loss: 0.5943 - val_mean_absolute_error: 0.5943\n",
      "Epoch 8/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.4371 - mean_absolute_error: 2.4371 - val_loss: 2.0192 - val_mean_absolute_error: 2.0192\n",
      "Epoch 9/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.7169 - mean_absolute_error: 2.7169 - val_loss: 2.2742 - val_mean_absolute_error: 2.2742\n",
      "Epoch 10/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 3.5480 - mean_absolute_error: 3.5480 - val_loss: 3.4657 - val_mean_absolute_error: 3.4657\n",
      "Epoch 11/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.2315 - mean_absolute_error: 2.2315 - val_loss: 2.4080 - val_mean_absolute_error: 2.4080\n",
      "Epoch 12/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.5500 - mean_absolute_error: 2.5500 - val_loss: 0.8060 - val_mean_absolute_error: 0.8060\n",
      "Epoch 13/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.5207 - mean_absolute_error: 2.5207 - val_loss: 0.6393 - val_mean_absolute_error: 0.6393\n",
      "Epoch 14/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7666 - mean_absolute_error: 1.7666 - val_loss: 2.7787 - val_mean_absolute_error: 2.7787\n",
      "Epoch 15/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.6567 - mean_absolute_error: 1.6567 - val_loss: 0.5924 - val_mean_absolute_error: 0.5924\n",
      "Epoch 16/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.0663 - mean_absolute_error: 2.0663 - val_loss: 1.4042 - val_mean_absolute_error: 1.4042\n",
      "Epoch 17/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 3.0644 - mean_absolute_error: 3.0644 - val_loss: 3.0728 - val_mean_absolute_error: 3.0728\n",
      "Epoch 18/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.6913 - mean_absolute_error: 2.6913 - val_loss: 2.7063 - val_mean_absolute_error: 2.7063\n",
      "Epoch 19/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 2.5473 - mean_absolute_error: 2.5473 - val_loss: 5.7648 - val_mean_absolute_error: 5.7648\n",
      "Epoch 20/20\n",
      "200/200 [==============================] - 1s 4ms/step - loss: 1.7474 - mean_absolute_error: 1.7474 - val_loss: 4.5535 - val_mean_absolute_error: 4.5535\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x245c3360f70>"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_model6 = Sequential()\n",
    "\n",
    "# The Input Layer :\n",
    "NN_model6.add(Dense(128, kernel_initializer='normal',input_dim = x_train6.shape[1], activation='relu'))\n",
    "\n",
    "# The Hidden Layers :\n",
    "NN_model6.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model6.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "NN_model6.add(Dense(256, kernel_initializer='normal',activation='relu'))\n",
    "\n",
    "# The Output Layer :\n",
    "NN_model6.add(Dense(1, kernel_initializer='normal',activation='linear'))\n",
    "\n",
    "# Compile the network :\n",
    "NN_model6.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n",
    "NN_model6.summary()\n",
    "NN_model6.fit(x_train6, y_train6, epochs=20, batch_size=32, validation_split = 0.2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing Phase"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.3821685254921\n",
      "R2: 0.9999573875997594\n"
     ]
    }
   ],
   "source": [
    "output = l_reg_sge.predict(x_test6)\n",
    "models_performances[\"Linear\"][\"sgemm\"] = r2_score(y_test6, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Support vector regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 7614.418257595669\n",
      "R2: 0.15098021749924717\n"
     ]
    }
   ],
   "source": [
    "output = svr_rbf_sge.predict(x_test6)\n",
    "models_performances[\"SVM\"][\"sgemm\"] = r2_score(y_test6, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3. Decision tree regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.7919889999999998\n",
      "R2: 0.9999116919630923\n"
     ]
    }
   ],
   "source": [
    "output = dr_regr_sge.predict(x_test6)\n",
    "models_performances[\"DecisionTree\"][\"sgemm\"] = r2_score(y_test6, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4. Random forest regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 0.43628178772000126\n",
      "R2: 0.9999513538846977\n"
     ]
    }
   ],
   "source": [
    "output = r_f_sge.predict(x_test6)\n",
    "models_performances[\"RandomForest\"][\"sgemm\"] = r2_score(y_test6, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5. k-nearest neighbours regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 1.2470330437500006\n",
      "R2: 0.9998609538263123\n"
     ]
    }
   ],
   "source": [
    "output = kn_sge.predict(x_test6)\n",
    "models_performances[\"KNN\"][\"sgemm\"] = r2_score(y_test6, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 6. AdaBoost regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 44.478127974121556\n",
      "R2: 0.9950406177778638\n"
     ]
    }
   ],
   "source": [
    "output = ada_sge.predict(x_test6)\n",
    "models_performances[\"AdaBoost\"][\"sgemm\"] = r2_score(y_test6, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 7. Gaussian process regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 4753.205449820069\n",
      "R2: 0.47001000987015673\n"
     ]
    }
   ],
   "source": [
    "output = gpr_sge.predict(x_test6)\n",
    "models_performances[\"GaussianProcess\"][\"sgemm\"] = r2_score(y_test6, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output)))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8. Neural network regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE: 26.305300879963283\n",
      "R2: 0.9970669169887739\n"
     ]
    }
   ],
   "source": [
    "output = NN_model6.predict(x_test6)\n",
    "models_performances[\"NeuralNetwork\"][\"sgemm\"] = r2_score(y_test6, output)\n",
    "print('MSE: {}'.format(mean_squared_error(y_test6, output.flatten())))\n",
    "print(f'R2: {r2_score(y_test6, output)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Models' performances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Linear': 0.6750236646011906,\n",
       " 'SVM': -0.030428761672383273,\n",
       " 'DecisionTree': 0.45273192688009845,\n",
       " 'RandomForest': 0.6715782984409658,\n",
       " 'KNN': 0.4938141984009279,\n",
       " 'AdaBoost': 0.6203692937785957,\n",
       " 'GaussianProcess': 0.18800330352041947,\n",
       " 'NeuralNetwork': 0.5405366681505089}"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_sum = {model:0 for model in models}\n",
    "for m in models:\n",
    "    for d in datasets_name:\n",
    "        r2_sum[m] += models_performances[m][d] / len(datasets_name)\n",
    "r2_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Linear</th>\n",
       "      <th>SVM</th>\n",
       "      <th>DecisionTree</th>\n",
       "      <th>RandomForest</th>\n",
       "      <th>KNN</th>\n",
       "      <th>AdaBoost</th>\n",
       "      <th>GaussianProcess</th>\n",
       "      <th>NeuralNetwork</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>wine</th>\n",
       "      <td>0.328389</td>\n",
       "      <td>-0.219613</td>\n",
       "      <td>-0.086319</td>\n",
       "      <td>0.433514</td>\n",
       "      <td>0.137410</td>\n",
       "      <td>0.290042</td>\n",
       "      <td>0.218653</td>\n",
       "      <td>0.271986</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>communities</th>\n",
       "      <td>0.150363</td>\n",
       "      <td>0.081725</td>\n",
       "      <td>-0.506920</td>\n",
       "      <td>0.239176</td>\n",
       "      <td>0.040460</td>\n",
       "      <td>0.150434</td>\n",
       "      <td>0.170488</td>\n",
       "      <td>0.118992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>qsar</th>\n",
       "      <td>0.440237</td>\n",
       "      <td>0.224733</td>\n",
       "      <td>0.024616</td>\n",
       "      <td>0.370965</td>\n",
       "      <td>0.220695</td>\n",
       "      <td>0.347956</td>\n",
       "      <td>0.350037</td>\n",
       "      <td>0.432605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>facebook</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-0.024367</td>\n",
       "      <td>0.566850</td>\n",
       "      <td>0.522188</td>\n",
       "      <td>0.026535</td>\n",
       "      <td>0.526715</td>\n",
       "      <td>-0.002227</td>\n",
       "      <td>-0.110776</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>bike</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>-1.254883</td>\n",
       "      <td>0.998995</td>\n",
       "      <td>0.999586</td>\n",
       "      <td>0.999630</td>\n",
       "      <td>0.976472</td>\n",
       "      <td>0.173087</td>\n",
       "      <td>0.999748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>student</th>\n",
       "      <td>0.855921</td>\n",
       "      <td>0.560781</td>\n",
       "      <td>0.753017</td>\n",
       "      <td>0.878726</td>\n",
       "      <td>0.853974</td>\n",
       "      <td>0.859733</td>\n",
       "      <td>-0.056362</td>\n",
       "      <td>0.797086</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>concrete</th>\n",
       "      <td>0.625322</td>\n",
       "      <td>0.237214</td>\n",
       "      <td>0.871705</td>\n",
       "      <td>0.928519</td>\n",
       "      <td>0.671948</td>\n",
       "      <td>0.816562</td>\n",
       "      <td>0.180340</td>\n",
       "      <td>0.817586</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sgemm</th>\n",
       "      <td>0.999957</td>\n",
       "      <td>0.150980</td>\n",
       "      <td>0.999912</td>\n",
       "      <td>0.999951</td>\n",
       "      <td>0.999861</td>\n",
       "      <td>0.995041</td>\n",
       "      <td>0.470010</td>\n",
       "      <td>0.997067</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Average</th>\n",
       "      <td>0.675024</td>\n",
       "      <td>-0.030429</td>\n",
       "      <td>0.452732</td>\n",
       "      <td>0.671578</td>\n",
       "      <td>0.493814</td>\n",
       "      <td>0.620369</td>\n",
       "      <td>0.188003</td>\n",
       "      <td>0.540537</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               Linear       SVM  DecisionTree  RandomForest       KNN  \\\n",
       "wine         0.328389 -0.219613     -0.086319      0.433514  0.137410   \n",
       "communities  0.150363  0.081725     -0.506920      0.239176  0.040460   \n",
       "qsar         0.440237  0.224733      0.024616      0.370965  0.220695   \n",
       "facebook     1.000000 -0.024367      0.566850      0.522188  0.026535   \n",
       "bike         1.000000 -1.254883      0.998995      0.999586  0.999630   \n",
       "student      0.855921  0.560781      0.753017      0.878726  0.853974   \n",
       "concrete     0.625322  0.237214      0.871705      0.928519  0.671948   \n",
       "sgemm        0.999957  0.150980      0.999912      0.999951  0.999861   \n",
       "Average      0.675024 -0.030429      0.452732      0.671578  0.493814   \n",
       "\n",
       "             AdaBoost  GaussianProcess  NeuralNetwork  \n",
       "wine         0.290042         0.218653       0.271986  \n",
       "communities  0.150434         0.170488       0.118992  \n",
       "qsar         0.347956         0.350037       0.432605  \n",
       "facebook     0.526715        -0.002227      -0.110776  \n",
       "bike         0.976472         0.173087       0.999748  \n",
       "student      0.859733        -0.056362       0.797086  \n",
       "concrete     0.816562         0.180340       0.817586  \n",
       "sgemm        0.995041         0.470010       0.997067  \n",
       "Average      0.620369         0.188003       0.540537  "
      ]
     },
     "execution_count": 168,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_perf = pd.DataFrame.from_dict(models_performances)\n",
    "avg = pd.DataFrame([list(r2_sum.values())], columns=models, index=[\"Average\"])\n",
    "m_perf = m_perf.append(avg)\n",
    "m_perf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "t = np.arange(len(models))\n",
    "plt.figure(figsize=(15,5))\n",
    "plt.bar(t,r2_sum.values(),align='center')\n",
    "plt.xticks(t,list(r2_sum.keys()))\n",
    "plt.yticks(np.arange(-0.1,1,0.1))\n",
    "for index,data in enumerate(list(r2_sum.values())):\n",
    "    plt.text(x=index-0.1 , y =data+0.04 , s=f\"{round(data,3)}\" , fontdict=dict(fontsize=10))\n",
    "plt.title('Average $R^2$ score get by models for each dataset')\n",
    "plt.ylabel('$R^2 score$')\n",
    "plt.savefig('model_performances.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
